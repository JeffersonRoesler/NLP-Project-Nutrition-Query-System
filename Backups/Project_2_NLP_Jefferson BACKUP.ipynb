{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMsU9t-s8Scp"
      },
      "source": [
        "## NLP PROJECT #2\n",
        "\n",
        "### Student: Jefferson Roesler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwaG1nTZ_8Mu"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0hHgVzUu82fo"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the JSON file\n",
        "with open('foundationDownload.json', 'r') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3s3LefYQxbz",
        "outputId": "547f8746-4945-45c9-e100-68ce2ded5b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Description  Serving Size (g)  \\\n",
            "0                                 Hummus, commercial              33.9   \n",
            "1                               Tomatoes, grape, raw              49.7   \n",
            "2  Beans, snap, green, canned, regular pack, drai...             129.0   \n",
            "3                        Frankfurter, beef, unheated              48.6   \n",
            "4        Nuts, almonds, dry roasted, with salt added             135.0   \n",
            "\n",
            "   Calories  Protein  Carbohydrates    Fat  \n",
            "0     229.0     7.35          14.90  17.10  \n",
            "1     113.0     0.83           5.51   0.63  \n",
            "2      86.0     1.04           4.11   0.39  \n",
            "3    1310.0    11.70           2.89  28.00  \n",
            "4    2590.0    20.40          16.20  57.80  \n"
          ]
        }
      ],
      "source": [
        "# Extract the list of foods\n",
        "foods = data[\"FoundationFoods\"]\n",
        "\n",
        "# Flatten the data and include serving size\n",
        "def process_food_data_with_serving_size(foods):\n",
        "    processed_data = []\n",
        "    for food in foods:\n",
        "        # Extract food description\n",
        "        description = food.get(\"description\", \"Unknown\")\n",
        "\n",
        "        # Extract serving size (from 'foodPortions')\n",
        "        food_portions = food.get(\"foodPortions\", [])\n",
        "        if food_portions:\n",
        "            # Assume the first portion is the standard serving size\n",
        "            serving_size = food_portions[0].get(\"gramWeight\", 0)  # Weight in grams\n",
        "        else:\n",
        "            serving_size = 0  # Default if no portion info available\n",
        "\n",
        "        # Extract nutrients\n",
        "        nutrients = food.get(\"foodNutrients\", [])\n",
        "        nutrient_dict = {n[\"nutrient\"][\"name\"]: n[\"amount\"] for n in nutrients if \"amount\" in n}\n",
        "\n",
        "        # Keep only key nutrients and serving size\n",
        "        important_nutrients = {\n",
        "            \"Description\": description,\n",
        "            \"Serving Size (g)\": serving_size,\n",
        "            \"Calories\": nutrient_dict.get(\"Energy\", 0),\n",
        "            \"Protein\": nutrient_dict.get(\"Protein\", 0),\n",
        "            \"Carbohydrates\": nutrient_dict.get(\"Carbohydrate, by difference\", 0),\n",
        "            \"Fat\": nutrient_dict.get(\"Total lipid (fat)\", 0)\n",
        "        }\n",
        "        processed_data.append(important_nutrients)\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "# Process the food data with serving size\n",
        "processed_foods_with_serving_size = process_food_data_with_serving_size(foods)\n",
        "\n",
        "# Convert to a Pandas DataFrame for easier handling\n",
        "food_df_with_serving_size = pd.DataFrame(processed_foods_with_serving_size)\n",
        "\n",
        "# Display the first few rows\n",
        "print(food_df_with_serving_size.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GOmLv8v_5o8"
      },
      "source": [
        "## Add columns for calories/protein per gram.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBVYerHO8s0w",
        "outputId": "1bad75a0-d594-4402-e966-67aeeff816ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Description  Serving Size (g)  \\\n",
            "0                                 Hummus, commercial              33.9   \n",
            "1                               Tomatoes, grape, raw              49.7   \n",
            "2  Beans, snap, green, canned, regular pack, drai...             129.0   \n",
            "3                        Frankfurter, beef, unheated              48.6   \n",
            "4        Nuts, almonds, dry roasted, with salt added             135.0   \n",
            "\n",
            "   Calories  Protein  Carbohydrates    Fat  Calories per Gram  \\\n",
            "0     229.0     7.35          14.90  17.10           6.755162   \n",
            "1     113.0     0.83           5.51   0.63           2.273642   \n",
            "2      86.0     1.04           4.11   0.39           0.666667   \n",
            "3    1310.0    11.70           2.89  28.00          26.954733   \n",
            "4    2590.0    20.40          16.20  57.80          19.185185   \n",
            "\n",
            "   Protein per Gram  \n",
            "0          0.216814  \n",
            "1          0.016700  \n",
            "2          0.008062  \n",
            "3          0.240741  \n",
            "4          0.151111  \n"
          ]
        }
      ],
      "source": [
        "# # Add new columns for calories and protein per gram\n",
        "# food_df_with_serving_size[\"Calories per Gram\"] = food_df_with_serving_size[\"Calories\"] / food_df_with_serving_size[\"Serving Size (g)\"]\n",
        "# food_df_with_serving_size[\"Protein per Gram\"] = food_df_with_serving_size[\"Protein\"] / food_df_with_serving_size[\"Serving Size (g)\"]\n",
        "\n",
        "# # Replace infinite or NaN values (e.g., where serving size is 0)\n",
        "# food_df_with_serving_size.replace([float('inf'), float('-inf')], 0, inplace=True)\n",
        "# food_df_with_serving_size.fillna(0, inplace=True)\n",
        "\n",
        "# # Display the updated DataFrame\n",
        "# print(food_df_with_serving_size.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Function to add Protein and Calories columns"
      ],
      "metadata": {
        "id": "cHW7ESQMs0tB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace zero Serving Size (g) with NaN for proper handling\n",
        "food_df_with_serving_size[\"Serving Size (g)\"] = food_df_with_serving_size[\"Serving Size (g)\"].replace(0, pd.NA)\n",
        "\n",
        "# Replace NaN in Serving Size (g) with median or group-based imputed value if not already done\n",
        "# Example: Global median\n",
        "median_serving_size = food_df_with_serving_size[\"Serving Size (g)\"].median()\n",
        "food_df_with_serving_size[\"Serving Size (g)\"].fillna(median_serving_size, inplace=True)\n",
        "\n",
        "# Recalculate Calories per Gram\n",
        "food_df_with_serving_size[\"Calories per Gram\"] = food_df_with_serving_size[\"Calories\"] / food_df_with_serving_size[\"Serving Size (g)\"]\n",
        "\n",
        "# Recalculate Protein per Gram\n",
        "food_df_with_serving_size[\"Protein per Gram\"] = food_df_with_serving_size[\"Protein\"] / food_df_with_serving_size[\"Serving Size (g)\"]\n",
        "\n",
        "# Replace infinite or NaN values in the derived columns\n",
        "food_df_with_serving_size.replace([float('inf'), float('-inf')], 0, inplace=True)\n",
        "food_df_with_serving_size.fillna(0, inplace=True)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(\"Updated DataFrame with recalculated values:\")\n",
        "print(food_df_with_serving_size[[\"Description\", \"Serving Size (g)\", \"Calories per Gram\", \"Protein per Gram\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN1Cs_vkszgp",
        "outputId": "28d59f0b-ee56-4bef-e1ab-69135e3b5fe7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated DataFrame with recalculated values:\n",
            "                                         Description  Serving Size (g)  \\\n",
            "0                                 Hummus, commercial              33.9   \n",
            "1                               Tomatoes, grape, raw              49.7   \n",
            "2  Beans, snap, green, canned, regular pack, drai...             129.0   \n",
            "3                        Frankfurter, beef, unheated              48.6   \n",
            "4        Nuts, almonds, dry roasted, with salt added             135.0   \n",
            "\n",
            "   Calories per Gram  Protein per Gram  \n",
            "0           6.755162          0.216814  \n",
            "1           2.273642          0.016700  \n",
            "2           0.666667          0.008062  \n",
            "3          26.954733          0.240741  \n",
            "4          19.185185          0.151111  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7b87070c5e2f>:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  food_df_with_serving_size[\"Serving Size (g)\"].fillna(median_serving_size, inplace=True)\n",
            "<ipython-input-3-7b87070c5e2f>:7: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  food_df_with_serving_size[\"Serving Size (g)\"].fillna(median_serving_size, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "0Oj9xvY2mzfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Food Description\n",
        "\n",
        "Description is too long and has useless info. I want to help the chatbot find later which food the user is talking about."
      ],
      "metadata": {
        "id": "WSPfI2ImlMtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to simplify and remove commas in food descriptions\n",
        "def simplify_description(description):\n",
        "    # Split by commas and join the first two parts without commas\n",
        "    parts = description.split(\",\")\n",
        "    return \" \".join(parts[:2]).strip() if len(parts) > 1 else description.strip()\n",
        "\n",
        "# Apply the simplification function to the Description column\n",
        "food_df_with_serving_size[\"Description\"] = food_df_with_serving_size[\"Description\"].apply(simplify_description)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(food_df_with_serving_size.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VSks1imlKaF",
        "outputId": "2577972f-e4a0-4733-bf0c-75d8b8fa83b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Description  Serving Size (g)  Calories  Protein  Carbohydrates  \\\n",
            "0  Hummus  commercial              33.9     229.0     7.35          14.90   \n",
            "1     Tomatoes  grape              49.7     113.0     0.83           5.51   \n",
            "2         Beans  snap             129.0      86.0     1.04           4.11   \n",
            "3   Frankfurter  beef              48.6    1310.0    11.70           2.89   \n",
            "4       Nuts  almonds             135.0    2590.0    20.40          16.20   \n",
            "\n",
            "     Fat  Calories per Gram  Protein per Gram  \n",
            "0  17.10           6.755162          0.216814  \n",
            "1   0.63           2.273642          0.016700  \n",
            "2   0.39           0.666667          0.008062  \n",
            "3  28.00          26.954733          0.240741  \n",
            "4  57.80          19.185185          0.151111  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wDSfL1S0_4VQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89aaf012-31eb-4f77-9aef-0104f195a2bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the dataset:\n",
            "Index(['Description', 'Serving Size (g)', 'Calories', 'Protein',\n",
            "       'Carbohydrates', 'Fat', 'Calories per Gram', 'Protein per Gram'],\n",
            "      dtype='object')\n",
            "\n",
            "Sample data:\n",
            "          Description  Serving Size (g)  Calories  Protein  Carbohydrates  \\\n",
            "0  Hummus  commercial              33.9     229.0     7.35          14.90   \n",
            "1     Tomatoes  grape              49.7     113.0     0.83           5.51   \n",
            "2         Beans  snap             129.0      86.0     1.04           4.11   \n",
            "3   Frankfurter  beef              48.6    1310.0    11.70           2.89   \n",
            "4       Nuts  almonds             135.0    2590.0    20.40          16.20   \n",
            "\n",
            "     Fat  Calories per Gram  Protein per Gram  \n",
            "0  17.10           6.755162          0.216814  \n",
            "1   0.63           2.273642          0.016700  \n",
            "2   0.39           0.666667          0.008062  \n",
            "3  28.00          26.954733          0.240741  \n",
            "4  57.80          19.185185          0.151111  \n"
          ]
        }
      ],
      "source": [
        "# Display all columns in the DataFrame\n",
        "print(\"Columns in the dataset:\")\n",
        "print(food_df_with_serving_size.columns)\n",
        "\n",
        "# Optionally, display the first few rows to inspect the data\n",
        "print(\"\\nSample data:\")\n",
        "print(food_df_with_serving_size.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Missing Values"
      ],
      "metadata": {
        "id": "PEVuD-Nzm2AH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "missing_values = food_df_with_serving_size.isnull().sum()\n",
        "\n",
        "# Calculate the percentage of missing values\n",
        "missing_percentage = (missing_values / len(food_df_with_serving_size)) * 100\n",
        "\n",
        "# Combine into a DataFrame for better readability\n",
        "missing_summary = pd.DataFrame({\n",
        "    \"Column\": food_df_with_serving_size.columns,\n",
        "    \"Missing Values\": missing_values,\n",
        "    \"Percentage (%)\": missing_percentage\n",
        "}).sort_values(by=\"Percentage (%)\", ascending=False)\n",
        "\n",
        "# Display the missing value summary\n",
        "print(missing_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GkArBCvmsxt",
        "outputId": "a25c28c3-e477-4242-ad21-bb65f6619289"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              Column  Missing Values  Percentage (%)\n",
            "Description              Description               0             0.0\n",
            "Serving Size (g)    Serving Size (g)               0             0.0\n",
            "Calories                    Calories               0             0.0\n",
            "Protein                      Protein               0             0.0\n",
            "Carbohydrates          Carbohydrates               0             0.0\n",
            "Fat                              Fat               0             0.0\n",
            "Calories per Gram  Calories per Gram               0             0.0\n",
            "Protein per Gram    Protein per Gram               0             0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero Values and Outliers"
      ],
      "metadata": {
        "id": "yIkK1xQep-8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count rows with Serving Size (g) equal to zero\n",
        "zero_serving_size_count = (food_df_with_serving_size[\"Serving Size (g)\"] == 0).sum()\n",
        "print(f\"Number of foods with zero serving size: {zero_serving_size_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkXGcapnms4b",
        "outputId": "0e415704-2269-4a12-8134-1660ed656996"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of foods with zero serving size: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for zero values in numeric columns\n",
        "zero_values_summary = (food_df_with_serving_size == 0).sum()\n",
        "\n",
        "# Calculate the percentage of zero values\n",
        "zero_values_percentage = (zero_values_summary / len(food_df_with_serving_size)) * 100\n",
        "\n",
        "# Combine into a DataFrame for readability\n",
        "zero_summary = pd.DataFrame({\n",
        "    \"Column\": food_df_with_serving_size.columns,\n",
        "    \"Zero Values\": zero_values_summary,\n",
        "    \"Percentage (%)\": zero_values_percentage\n",
        "}).sort_values(by=\"Percentage (%)\", ascending=False)\n",
        "\n",
        "# Display the zero value summary\n",
        "print(\"Zero Value Summary:\")\n",
        "print(zero_summary)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCk_yQgSmsz4",
        "outputId": "72e852ac-39ac-4ded-e376-d14624ba247a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero Value Summary:\n",
            "                              Column  Zero Values  Percentage (%)\n",
            "Calories                    Calories          219       69.303797\n",
            "Calories per Gram  Calories per Gram          219       69.303797\n",
            "Carbohydrates          Carbohydrates           59       18.670886\n",
            "Protein                      Protein           14        4.430380\n",
            "Protein per Gram    Protein per Gram           14        4.430380\n",
            "Fat                              Fat           10        3.164557\n",
            "Description              Description            0        0.000000\n",
            "Serving Size (g)    Serving Size (g)            0        0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Calories Column = zero"
      ],
      "metadata": {
        "id": "lWFSNZz-tfm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where Calories is equal to zero\n",
        "zero_calories_rows = food_df_with_serving_size[food_df_with_serving_size[\"Calories\"] == 0]\n",
        "\n",
        "# Display the rows with zero Calories\n",
        "print(\"Rows with zero Calories:\")\n",
        "print(zero_calories_rows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlP5Hr4MtK-1",
        "outputId": "30bcefa9-95c3-4adf-eb2e-51bd4f173bbd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows with zero Calories:\n",
            "              Description  Serving Size (g)  Calories  Protein  Carbohydrates  \\\n",
            "61            Salt  table               6.1       0.0     0.00            0.0   \n",
            "74             Beans  Dry              97.3       0.0    25.50            0.0   \n",
            "75             Beans  Dry              97.3       0.0    21.30            0.0   \n",
            "76             Beans  Dry              97.3       0.0    23.30            0.0   \n",
            "77             Beans  Dry              97.3       0.0    25.60            0.0   \n",
            "..                    ...               ...       ...      ...            ...   \n",
            "311   Sorghum bran  white              97.3       0.0    11.20           68.7   \n",
            "312  Sorghum flour  white              97.3       0.0    10.20           73.5   \n",
            "313  Sorghum grain  white              97.3       0.0    10.20           74.9   \n",
            "314  Sorghum  whole grain              97.3       0.0    10.10           73.6   \n",
            "315   Plantains  overripe              97.3       0.0     1.17           29.2   \n",
            "\n",
            "      Fat  Calories per Gram  Protein per Gram  \n",
            "61   0.00                0.0          0.000000  \n",
            "74   1.04                0.0          0.262076  \n",
            "75   1.16                0.0          0.218911  \n",
            "76   0.86                0.0          0.239466  \n",
            "77   1.12                0.0          0.263104  \n",
            "..    ...                ...               ...  \n",
            "311  9.26                0.0          0.115108  \n",
            "312  3.24                0.0          0.104830  \n",
            "313  3.26                0.0          0.104830  \n",
            "314  4.22                0.0          0.103803  \n",
            "315  0.99                0.0          0.012025  \n",
            "\n",
            "[219 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 10 rows with zero Calories\n",
        "print(zero_calories_rows.head(10))\n",
        "\n",
        "# Optionally, export the filtered rows to a CSV for analysis\n",
        "zero_calories_rows.to_csv(\"zero_calories_rows.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jon138DCtLA2",
        "outputId": "8d103273-3f7b-42b0-8c88-cc753a803192"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Description  Serving Size (g)  Calories  Protein  Carbohydrates   Fat  \\\n",
            "61  Salt  table               6.1       0.0      0.0            0.0  0.00   \n",
            "74   Beans  Dry              97.3       0.0     25.5            0.0  1.04   \n",
            "75   Beans  Dry              97.3       0.0     21.3            0.0  1.16   \n",
            "76   Beans  Dry              97.3       0.0     23.3            0.0  0.86   \n",
            "77   Beans  Dry              97.3       0.0     25.6            0.0  1.12   \n",
            "78   Beans  Dry              97.3       0.0     26.8            0.0  1.14   \n",
            "79   Beans  Dry              97.3       0.0     24.6            0.0  1.28   \n",
            "80   Beans  Dry              97.3       0.0     25.2            0.0  1.44   \n",
            "81   Beans  Dry              97.3       0.0     24.4            0.0  1.23   \n",
            "82   Beans  Dry              97.3       0.0     25.0            0.0  1.03   \n",
            "\n",
            "    Calories per Gram  Protein per Gram  \n",
            "61                0.0          0.000000  \n",
            "74                0.0          0.262076  \n",
            "75                0.0          0.218911  \n",
            "76                0.0          0.239466  \n",
            "77                0.0          0.263104  \n",
            "78                0.0          0.275437  \n",
            "79                0.0          0.252826  \n",
            "80                0.0          0.258993  \n",
            "81                0.0          0.250771  \n",
            "82                0.0          0.256937  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Validate Zero Calories:\n",
        "Foods like salt are valid with zero calories, so these can be excluded from further processing.\n",
        "For the remaining rows, we can estimate calories based on macronutrient values using the standard formula:\n",
        "\n",
        "Calories\n",
        "=\n",
        "4\n",
        "×\n",
        "\n",
        "Protein (g)\n",
        "+\n",
        "4\n",
        "×\n",
        "\n",
        "Carbohydrates (g)\n",
        "+\n",
        "9\n",
        "×\n",
        "Fat (g)\n",
        "\n",
        "Calories=4×Protein (g)+4×Carbohydrates (g)+9×Fat (g)\n",
        "\n",
        "2. Fill Missing Calories:\n",
        "Replace zero calorie values with the calculated estimates.\n"
      ],
      "metadata": {
        "id": "LALuTr5Ct70Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify rows where Calories is zero but Protein, Carbohydrates, or Fat are non-zero\n",
        "non_salt_rows = food_df_with_serving_size[\n",
        "    (food_df_with_serving_size[\"Calories\"] == 0) &\n",
        "    ((food_df_with_serving_size[\"Protein\"] > 0) |\n",
        "     (food_df_with_serving_size[\"Carbohydrates\"] > 0) |\n",
        "     (food_df_with_serving_size[\"Fat\"] > 0))\n",
        "]\n",
        "\n",
        "# Calculate calories using the macronutrient formula\n",
        "food_df_with_serving_size.loc[non_salt_rows.index, \"Calories\"] = (\n",
        "    4 * food_df_with_serving_size.loc[non_salt_rows.index, \"Protein\"] +\n",
        "    4 * food_df_with_serving_size.loc[non_salt_rows.index, \"Carbohydrates\"] +\n",
        "    9 * food_df_with_serving_size.loc[non_salt_rows.index, \"Fat\"]\n",
        ")\n",
        "\n",
        "# Recalculate Calories per Gram\n",
        "food_df_with_serving_size[\"Calories per Gram\"] = (\n",
        "    food_df_with_serving_size[\"Calories\"] / food_df_with_serving_size[\"Serving Size (g)\"]\n",
        ")\n",
        "\n",
        "# Replace infinite or NaN values\n",
        "food_df_with_serving_size.replace([float('inf'), float('-inf')], 0, inplace=True)\n",
        "food_df_with_serving_size.fillna(0, inplace=True)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(\"Updated rows with previously zero Calories:\")\n",
        "print(food_df_with_serving_size.loc[non_salt_rows.index])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thLeEIj1tLFI",
        "outputId": "6ccf45ac-f5f4-4f74-8dfa-c3e2ace2da26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated rows with previously zero Calories:\n",
            "              Description  Serving Size (g)  Calories  Protein  Carbohydrates  \\\n",
            "74             Beans  Dry              97.3    111.36    25.50            0.0   \n",
            "75             Beans  Dry              97.3     95.64    21.30            0.0   \n",
            "76             Beans  Dry              97.3    100.94    23.30            0.0   \n",
            "77             Beans  Dry              97.3    112.48    25.60            0.0   \n",
            "78             Beans  Dry              97.3    117.46    26.80            0.0   \n",
            "..                    ...               ...       ...      ...            ...   \n",
            "311   Sorghum bran  white              97.3    402.94    11.20           68.7   \n",
            "312  Sorghum flour  white              97.3    363.96    10.20           73.5   \n",
            "313  Sorghum grain  white              97.3    369.74    10.20           74.9   \n",
            "314  Sorghum  whole grain              97.3    372.78    10.10           73.6   \n",
            "315   Plantains  overripe              97.3    130.39     1.17           29.2   \n",
            "\n",
            "      Fat  Calories per Gram  Protein per Gram  \n",
            "74   1.04           1.144502          0.262076  \n",
            "75   1.16           0.982939          0.218911  \n",
            "76   0.86           1.037410          0.239466  \n",
            "77   1.12           1.156012          0.263104  \n",
            "78   1.14           1.207194          0.275437  \n",
            "..    ...                ...               ...  \n",
            "311  9.26           4.141213          0.115108  \n",
            "312  3.24           3.740596          0.104830  \n",
            "313  3.26           3.800000          0.104830  \n",
            "314  4.22           3.831244          0.103803  \n",
            "315  0.99           1.340082          0.012025  \n",
            "\n",
            "[210 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where Protein and Fat are both zero\n",
        "zero_protein_fat = food_df_with_serving_size[\n",
        "    (food_df_with_serving_size[\"Protein\"] == 0) &\n",
        "    (food_df_with_serving_size[\"Fat\"] == 0)\n",
        "]\n",
        "\n",
        "# Display these rows for review\n",
        "print(\"Rows with zero Protein and zero Fat:\")\n",
        "print(zero_protein_fat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jguQ2cvEtLHo",
        "outputId": "74336a9e-09ab-4ca0-b02c-c381bd46f80e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows with zero Protein and zero Fat:\n",
            "        Description  Serving Size (g)  Calories  Protein  Carbohydrates  Fat  \\\n",
            "61      Salt  table               6.1       0.0      0.0            0.0  0.0   \n",
            "95      Oil  canola              90.9       0.0      0.0            0.0  0.0   \n",
            "96        Oil  corn              91.3       0.0      0.0            0.0  0.0   \n",
            "97     Oil  soybean              91.3       0.0      0.0            0.0  0.0   \n",
            "98       Oil  olive              90.7       0.0      0.0            0.0  0.0   \n",
            "126     Oil  peanut              97.3       0.0      0.0            0.0  0.0   \n",
            "127  Oil  sunflower              97.3       0.0      0.0            0.0  0.0   \n",
            "128  Oil  safflower              97.3       0.0      0.0            0.0  0.0   \n",
            "129      Oil  olive              97.3       0.0      0.0            0.0  0.0   \n",
            "\n",
            "     Calories per Gram  Protein per Gram  \n",
            "61                 0.0               0.0  \n",
            "95                 0.0               0.0  \n",
            "96                 0.0               0.0  \n",
            "97                 0.0               0.0  \n",
            "98                 0.0               0.0  \n",
            "126                0.0               0.0  \n",
            "127                0.0               0.0  \n",
            "128                0.0               0.0  \n",
            "129                0.0               0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop Rows with All Zero Values"
      ],
      "metadata": {
        "id": "KWd29X0LvAyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows where Protein, Fat, and Calories are all zero\n",
        "cleaned_df = food_df_with_serving_size[\n",
        "    ~((food_df_with_serving_size[\"Protein\"] == 0) &\n",
        "      (food_df_with_serving_size[\"Fat\"] == 0) &\n",
        "      (food_df_with_serving_size[\"Calories\"] == 0))\n",
        "]\n",
        "\n",
        "# Display the number of rows after cleaning\n",
        "print(f\"Number of rows after dropping invalid rows: {len(cleaned_df)}\")\n",
        "print(cleaned_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJRO1OlSu0KF",
        "outputId": "51c69fc3-5519-4c7a-b894-1460378a11d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows after dropping invalid rows: 307\n",
            "          Description  Serving Size (g)  Calories  Protein  Carbohydrates  \\\n",
            "0  Hummus  commercial              33.9     229.0     7.35          14.90   \n",
            "1     Tomatoes  grape              49.7     113.0     0.83           5.51   \n",
            "2         Beans  snap             129.0      86.0     1.04           4.11   \n",
            "3   Frankfurter  beef              48.6    1310.0    11.70           2.89   \n",
            "4       Nuts  almonds             135.0    2590.0    20.40          16.20   \n",
            "\n",
            "     Fat  Calories per Gram  Protein per Gram  \n",
            "0  17.10           6.755162          0.216814  \n",
            "1   0.63           2.273642          0.016700  \n",
            "2   0.39           0.666667          0.008062  \n",
            "3  28.00          26.954733          0.240741  \n",
            "4  57.80          19.185185          0.151111  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cleaned_df[\n",
        "    (cleaned_df[\"Protein\"] == 0) &\n",
        "    (cleaned_df[\"Fat\"] == 0) &\n",
        "    (cleaned_df[\"Calories\"] == 0)\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbl2bRj0u0MW",
        "outputId": "07305700-64c5-45fb-fc89-8d9d26b06436"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Description, Serving Size (g), Calories, Protein, Carbohydrates, Fat, Calories per Gram, Protein per Gram]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Rows before cleaning: {len(food_df_with_serving_size)}\")\n",
        "print(f\"Rows after cleaning: {len(cleaned_df)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLzlwLRVu0Ol",
        "outputId": "3e01a592-4e5d-458c-a382-92c654ce2524"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows before cleaning: 316\n",
            "Rows after cleaning: 307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dividing foods in High-Protein, Low-Carb, High-Fat and Balanced."
      ],
      "metadata": {
        "id": "5WrYBW_PwEAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define thresholds for macronutrient-based categorization\n",
        "def macronutrient_category(row):\n",
        "    if row[\"Protein\"] > 15:\n",
        "        return \"High-Protein\"\n",
        "    elif row[\"Carbohydrates\"] < 5:\n",
        "        return \"Low-Carb\"\n",
        "    elif row[\"Fat\"] > 10:\n",
        "        return \"High-Fat\"\n",
        "    else:\n",
        "        return \"Balanced\"\n",
        "\n",
        "# Apply the function to assign macronutrient profiles\n",
        "food_df_with_serving_size[\"Macronutrient Profile\"] = food_df_with_serving_size.apply(macronutrient_category, axis=1)\n",
        "\n",
        "# Display a sample of foods with macronutrient profiles\n",
        "print(food_df_with_serving_size[[\"Description\", \"Macronutrient Profile\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcArf3XLu0Q1",
        "outputId": "8a8428fc-4aa6-4841-d0fc-36a9932ef83c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Description Macronutrient Profile\n",
            "0  Hummus  commercial              High-Fat\n",
            "1     Tomatoes  grape              Balanced\n",
            "2         Beans  snap              Low-Carb\n",
            "3   Frankfurter  beef              Low-Carb\n",
            "4       Nuts  almonds          High-Protein\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple ChatBot to test"
      ],
      "metadata": {
        "id": "NU8AWvfqwwDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to simulate chatbot responses\n",
        "def chatbot_response(query):\n",
        "    query = query.lower()\n",
        "\n",
        "    if \"high-protein\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Macronutrient Profile\"] == \"High-Protein\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some high-protein foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"low-carb\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Macronutrient Profile\"] == \"Low-Carb\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some low-carb foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"balanced\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Macronutrient Profile\"] == \"Balanced\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some foods with balanced macronutrients: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"high-protein and low-carb\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            (food_df_with_serving_size[\"Macronutrient Profile\"] == \"High-Protein\") &\n",
        "            (food_df_with_serving_size[\"Carbohydrates\"] < 5)\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some high-protein and low-carb foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    else:\n",
        "        return \"I'm sorry, I didn't understand that. Can you ask about high-protein, low-carb, or balanced foods?\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QSgxOFyKu0S_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test example queries\n",
        "print(chatbot_response(\"What are some high-protein foods?\"))\n",
        "print(chatbot_response(\"List low-carb options.\"))\n",
        "print(chatbot_response(\"What foods are balanced in macronutrients?\"))\n",
        "print(chatbot_response(\"Can you suggest high-protein and low-carb foods?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxUrcd7Hw1ki",
        "outputId": "bc26c27c-4086-40da-d68a-0bc264839a78"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some high-protein foods: Nuts  almonds, Egg  white, Cheese  parmesan, Cheese  pasteurized process, Seeds  sunflower seed kernels, Cheese  cheddar, Cheese  mozzarella, Egg  whole, Egg  yolk, Egg  yolk...\n",
            "Here are some low-carb foods: Beans  snap, Frankfurter  beef, Kale  raw, Egg  whole, Egg  white, Pickles  cucumber, Cheese  cottage, Yogurt  Greek, Oil  coconut, Olives  green...\n",
            "Here are some foods with balanced macronutrients: Tomatoes  grape, Grapefruit juice  white, Peaches  yellow, Bread  white, Kale  frozen, Mustard  prepared, Kiwifruit  green, Nectarines  raw, Yogurt  Greek, Sauce  pasta...\n",
            "Here are some high-protein foods: Nuts  almonds, Egg  white, Cheese  parmesan, Cheese  pasteurized process, Seeds  sunflower seed kernels, Cheese  cheddar, Cheese  mozzarella, Egg  whole, Egg  yolk, Egg  yolk...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# More examples\n",
        "\n",
        "print(chatbot_response(\"Tell me which high-protein food I can eat?\"))\n",
        "print(chatbot_response(\"List low-carb vegetables.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc_KEbbrxBQf",
        "outputId": "6d339cff-5002-4b14-cd3d-6a136603c388"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some high-protein foods: Nuts  almonds, Egg  white, Cheese  parmesan, Cheese  pasteurized process, Seeds  sunflower seed kernels, Cheese  cheddar, Cheese  mozzarella, Egg  whole, Egg  yolk, Egg  yolk...\n",
            "Here are some low-carb foods: Beans  snap, Frankfurter  beef, Kale  raw, Egg  whole, Egg  white, Pickles  cucumber, Cheese  cottage, Yogurt  Greek, Oil  coconut, Olives  green...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Increasing Base Knownledge\n"
      ],
      "metadata": {
        "id": "jlsVKtbax6oK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to categorize foods based on calorie content\n",
        "def caloric_density(row):\n",
        "    if row[\"Calories per Gram\"] > 2:\n",
        "        return \"High-Calorie\"\n",
        "    elif row[\"Calories per Gram\"] > 1:\n",
        "        return \"Moderate-Calorie\"\n",
        "    else:\n",
        "        return \"Low-Calorie\"\n",
        "\n",
        "food_df_with_serving_size[\"Caloric Density\"] = food_df_with_serving_size.apply(caloric_density, axis=1)\n",
        "\n",
        "# Display a sample of the updated dataset\n",
        "print(\"Sample of foods with Calorie Category:\")\n",
        "print(food_df_with_serving_size[[\"Description\", \"Calories\", \"Caloric Density\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM6F1tbEx6Df",
        "outputId": "c3e7442a-5196-47dd-ce91-7f0221301861"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of foods with Calorie Category:\n",
            "          Description  Calories Caloric Density\n",
            "0  Hummus  commercial     229.0    High-Calorie\n",
            "1     Tomatoes  grape     113.0    High-Calorie\n",
            "2         Beans  snap      86.0     Low-Calorie\n",
            "3   Frankfurter  beef    1310.0    High-Calorie\n",
            "4       Nuts  almonds    2590.0    High-Calorie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to categorize foods based on protein content\n",
        "def protein_category(row):\n",
        "    if row[\"Protein\"] > 25:\n",
        "        return \"Very High-Protein\"\n",
        "    elif row[\"Protein\"] > 15:\n",
        "        return \"High-Protein\"\n",
        "    elif row[\"Protein\"] > 5:\n",
        "        return \"Moderate-Protein\"\n",
        "    else:\n",
        "        return \"Low-Protein\"\n",
        "\n",
        "# Apply the categorization function to the dataset\n",
        "food_df_with_serving_size[\"Protein Category\"] = food_df_with_serving_size.apply(protein_category, axis=1)\n",
        "\n",
        "# Display a sample of the updated dataset\n",
        "print(\"Sample of foods with Protein Category:\")\n",
        "print(food_df_with_serving_size[[\"Description\", \"Protein\", \"Protein Category\"]].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVfN-de_x6Fx",
        "outputId": "ae8364f6-cff2-487b-fd91-0ea7100666e8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of foods with Protein Category:\n",
            "          Description  Protein  Protein Category\n",
            "0  Hummus  commercial     7.35  Moderate-Protein\n",
            "1     Tomatoes  grape     0.83       Low-Protein\n",
            "2         Beans  snap     1.04       Low-Protein\n",
            "3   Frankfurter  beef    11.70  Moderate-Protein\n",
            "4       Nuts  almonds    20.40      High-Protein\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Updated Chatbot"
      ],
      "metadata": {
        "id": "qlRgRMSay-ZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle chatbot responses for macronutrient, protein, and caloric density queries\n",
        "def chatbot_response(query):\n",
        "    query = query.lower()\n",
        "\n",
        "    # Macronutrient Profile Queries\n",
        "    if \"high-protein and low-carb\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            (food_df_with_serving_size[\"Macronutrient Profile\"] == \"High-Protein\") &\n",
        "            (food_df_with_serving_size[\"Carbohydrates\"] < 5)\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some high-protein and low-carb foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"high-protein\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Macronutrient Profile\"] == \"High-Protein\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some high-protein foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"low-carb\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Macronutrient Profile\"] == \"Low-Carb\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some low-carb foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"balanced\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Macronutrient Profile\"] == \"Balanced\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some foods with balanced macronutrients: {', '.join(result[:10])}...\"\n",
        "\n",
        "    # Protein Category Queries\n",
        "    elif \"very high-protein\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Protein Category\"] == \"Very High-Protein\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some very high-protein foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"high-protein\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Protein Category\"] == \"High-Protein\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some high-protein foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"moderate-protein\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Protein Category\"] == \"Moderate-Protein\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some moderate-protein foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"low-protein\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Protein Category\"] == \"Low-Protein\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some low-protein foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    # Caloric Density Queries\n",
        "    elif \"high-calorie\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Caloric Density\"] == \"High-Calorie\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some high-calorie foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"moderate-calorie\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Caloric Density\"] == \"Moderate-Calorie\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some moderate-calorie foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    elif \"low-calorie\" in query:\n",
        "        result = food_df_with_serving_size[\n",
        "            food_df_with_serving_size[\"Caloric Density\"] == \"Low-Calorie\"\n",
        "        ][\"Description\"].tolist()\n",
        "        return f\"Here are some low-calorie foods: {', '.join(result[:10])}...\"\n",
        "\n",
        "    # Default Response\n",
        "    else:\n",
        "        return \"I'm sorry, I didn't understand that. Can you ask about specific protein, macronutrient, or caloric density levels?\"\n"
      ],
      "metadata": {
        "id": "iAb9i6uqx6IB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test macronutrient profile queries\n",
        "print(chatbot_response(\"What are some high-protein foods?\"))\n",
        "print(chatbot_response(\"List low-carb options.\"))\n",
        "print(chatbot_response(\"What foods are balanced in macronutrients?\"))\n",
        "print(chatbot_response(\"Can you suggest high-protein and low-carb foods?\"))\n",
        "\n",
        "# Test protein category queries\n",
        "print(chatbot_response(\"What are very high-protein foods?\"))\n",
        "print(chatbot_response(\"What foods are low in protein?\"))\n",
        "\n",
        "# Test calorie category queries\n",
        "print(chatbot_response(\"What are some high-calorie foods?\"))\n",
        "print(chatbot_response(\"What are moderate-calorie foods?\"))\n",
        "print(chatbot_response(\"Can you suggest low-calorie foods?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hjBKMJuzBwi",
        "outputId": "18c62976-2470-439f-a21e-8661694cf7e2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some high-protein foods: Nuts  almonds, Egg  white, Cheese  parmesan, Cheese  pasteurized process, Seeds  sunflower seed kernels, Cheese  cheddar, Cheese  mozzarella, Egg  whole, Egg  yolk, Egg  yolk...\n",
            "Here are some low-carb foods: Beans  snap, Frankfurter  beef, Kale  raw, Egg  whole, Egg  white, Pickles  cucumber, Cheese  cottage, Yogurt  Greek, Oil  coconut, Olives  green...\n",
            "Here are some foods with balanced macronutrients: Tomatoes  grape, Grapefruit juice  white, Peaches  yellow, Bread  white, Kale  frozen, Mustard  prepared, Kiwifruit  green, Nectarines  raw, Yogurt  Greek, Sauce  pasta...\n",
            "Here are some high-protein and low-carb foods: Cheese  cheddar, Cheese  mozzarella, Egg  whole, Egg  yolk, Egg  yolk, Chicken  broilers or fryers, Chicken  broiler or fryers, Ham  sliced, Fish  haddock, Fish  tuna...\n",
            "Here are some high-protein foods: Nuts  almonds, Egg  white, Cheese  parmesan, Cheese  pasteurized process, Seeds  sunflower seed kernels, Cheese  cheddar, Cheese  mozzarella, Egg  whole, Egg  yolk, Egg  yolk...\n",
            "I'm sorry, I didn't understand that. Can you ask about specific protein, macronutrient, or caloric density levels?\n",
            "Here are some high-calorie foods: Hummus  commercial, Tomatoes  grape, Frankfurter  beef, Nuts  almonds, Egg  whole, Egg  white, Egg  white, Onion rings  breaded, Cheese  parmesan, Cheese  pasteurized process...\n",
            "Here are some moderate-calorie foods: Kale  raw, Peaches  yellow, Kale  frozen, Cheese  cottage, Chicken  broilers or fryers, Sauce  pasta, Fish  haddock, Fish  pollock, Restaurant  Latino, Restaurant  Latino...\n",
            "Here are some low-calorie foods: Beans  snap, Pickles  cucumber, Grapefruit juice  white, Mustard  prepared, Nectarines  raw, Yogurt  Greek, Tomatoes  canned, Beef  round, Beef  round, Beef  short loin...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tune GPT-2"
      ],
      "metadata": {
        "id": "QFUKgn2SzwOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Conversational Training Data"
      ],
      "metadata": {
        "id": "n9LfSIcSzy7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate conversational training data\n",
        "def generate_conversational_data(df):\n",
        "    training_data = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # Generate questions based on Macronutrient Profile\n",
        "        if \"Macronutrient Profile\" in df.columns:\n",
        "            if row[\"Macronutrient Profile\"] == \"High-Protein\":\n",
        "                question = \"User: What are some high-protein foods?\"\n",
        "                answer = f\"Bot: {row['Description']}.\"\n",
        "                training_data.append(f\"{question}\\n{answer}<|endoftext|>\")\n",
        "\n",
        "            elif row[\"Macronutrient Profile\"] == \"Low-Carb\":\n",
        "                question = \"User: What are some low-carb foods?\"\n",
        "                answer = f\"Bot: {row['Description']}.\"\n",
        "                training_data.append(f\"{question}\\n{answer}<|endoftext|>\")\n",
        "\n",
        "            elif row[\"Macronutrient Profile\"] == \"Balanced\":\n",
        "                question = \"User: What foods are balanced in macronutrients?\"\n",
        "                answer = f\"Bot: {row['Description']}.\"\n",
        "                training_data.append(f\"{question}\\n{answer}<|endoftext|>\")\n",
        "\n",
        "        # Generate questions based on Caloric Density\n",
        "        if \"Caloric Density\" in df.columns:\n",
        "            if row[\"Caloric Density\"] == \"High-Calorie\":\n",
        "                question = \"User: What are some high-calorie foods?\"\n",
        "                answer = f\"Bot: {row['Description']}.\"\n",
        "                training_data.append(f\"{question}\\n{answer}<|endoftext|>\")\n",
        "\n",
        "            elif row[\"Caloric Density\"] == \"Moderate-Calorie\":\n",
        "                question = \"User: What are some moderate-calorie foods?\"\n",
        "                answer = f\"Bot: {row['Description']}.\"\n",
        "                training_data.append(f\"{question}\\n{answer}<|endoftext|>\")\n",
        "\n",
        "            elif row[\"Caloric Density\"] == \"Low-Calorie\":\n",
        "                question = \"User: What are some low-calorie foods?\"\n",
        "                answer = f\"Bot: {row['Description']}.\"\n",
        "                training_data.append(f\"{question}\\n{answer}<|endoftext|>\")\n",
        "\n",
        "        # Generate questions based on other food categories (if applicable)\n",
        "        if \"Food Type\" in df.columns:\n",
        "            if row[\"Food Type\"] == \"Fruit\":\n",
        "                question = \"User: What are some fruits?\"\n",
        "                answer = f\"Bot: {row['Description']}.\"\n",
        "                training_data.append(f\"{question}\\n{answer}<|endoftext|>\")\n",
        "\n",
        "    return training_data\n",
        "\n",
        "# Apply the function to your dataset\n",
        "training_texts = generate_conversational_data(food_df_with_serving_size)\n",
        "\n",
        "# Save the training data to a text file\n",
        "with open(\"conversational_training_data.txt\", \"w\") as file:\n",
        "    file.write(\"\\n\".join(training_texts))\n",
        "\n",
        "print(f\"Generated {len(training_texts)} conversational training examples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5vLIkYzzvY_",
        "outputId": "da2d6c75-9e7a-4f21-9b92-98cc47c3f009"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 620 conversational training examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning using generated conversational training examples"
      ],
      "metadata": {
        "id": "wWeTa8ju1Lfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install transformers datasets torch\n"
      ],
      "metadata": {
        "id": "yfAx2M2vzvbW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the text dataset\n",
        "dataset = load_dataset(\"text\", data_files={\"train\": \"conversational_training_data.txt\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "aba2cc363dde45c38f3d8cfba3d3c744",
            "d2102069b54041df905f738869c0fe2d",
            "933831a6bae1459095ffc1f02faa57ec",
            "287aabe26eac49c0a0966f4e680cba28",
            "bc033873f40a4f0c86bda589455695c3",
            "0e8cc5f3d1594cc38ca4855a02c04071",
            "f14e056c3b744c86bc33d4c68e9f7c93",
            "b0d8b937e6c343bda7935cc205b6659f",
            "d6395cb7d3d84e91acaf9f3a2e5fcdde",
            "7aa905bbb1304472b91641932d6c5412",
            "686632dbf84b4f7fb1a9443d67b4c88f"
          ]
        },
        "id": "d7959DB_zvds",
        "outputId": "e7712bab-feff-43cf-84c5-361f351e1c2d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aba2cc363dde45c38f3d8cfba3d3c744"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "\n",
        "# Load GPT-2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    encodings = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        padding=\"max_length\",  #\n",
        "    )\n",
        "    encodings[\"labels\"] = encodings[\"input_ids\"].copy()  # Add labels\n",
        "    return encodings\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f1fdc9e5836b405d98b09381ef88af2e",
            "c3f659f5eea546349634a0897b6c5340",
            "3b1feec7784d45108e4be8bde771b16c",
            "613c3a386f1843c8b5f21d3b458e48dc",
            "2b3bf080fbcb427da4c34b5944a78d5c",
            "ef6cf1a86c464aa499a693a986f5f231",
            "9d31d49b4bcc40719281448b75756de2",
            "fd89a616e61c47438b922657e0c7b981",
            "af56b87b82d54c9f8adb0dd99058b914",
            "8fac20148555449f84ad4d0401c48848",
            "f85b164afc4c4bc3937e4c708c7a0a28"
          ]
        },
        "id": "bF5CwsSHzvf6",
        "outputId": "4ced1182-ddaf-4229-dae7-55e46e77a636"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1240 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1fdc9e5836b405d98b09381ef88af2e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "# Load GPT-2 model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n"
      ],
      "metadata": {
        "id": "cKGeqi9fzviF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=100,\n",
        "    report_to=[],  # Disable wandb and other reporting tools\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    tokenizer=tokenizer,  # Ensure tokenizer includes pad_token\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "zta0ZUb4zvkJ",
        "outputId": "92f7ad45-8436-4d81-d0e8-6080de93c652"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-54b54236b375>:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1550' max='1550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1550/1550 05:12, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.037700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.033900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.035200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.031300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.031100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.032400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.032700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.038100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.032200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.032600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.032300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.031200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.031300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.031100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1550, training_loss=0.032992726833589614, metrics={'train_runtime': 312.6605, 'train_samples_per_second': 19.83, 'train_steps_per_second': 4.957, 'total_flos': 405002649600000.0, 'train_loss': 0.032992726833589614, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model after training\n",
        "trainer.save_model(\"./gpt2-finetuned\")\n",
        "tokenizer.save_pretrained(\"./gpt2-finetuned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X6ms3Zb56b8",
        "outputId": "30a9baf5-2dd5-4c59-d869-5e8b739541dd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./gpt2-finetuned/tokenizer_config.json',\n",
              " './gpt2-finetuned/special_tokens_map.json',\n",
              " './gpt2-finetuned/vocab.json',\n",
              " './gpt2-finetuned/merges.txt',\n",
              " './gpt2-finetuned/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-finetuned\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-finetuned\")\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs, max_length=50, num_return_sequences=1, temperature=0.7)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test the chatbot\n",
        "print(generate_response(\"User: What are some high-protein foods?\\nBot:\"))\n",
        "print(generate_response(\"User: What are low-calorie foods?\\nBot:\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXrQFZ-Yzvob",
        "outputId": "42159c5b-9d6f-44e3-8b78-ca9396c54703"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What are some high-protein foods?\n",
            "Bot: Beans  Dry.\n",
            "User: What are low-calorie foods?\n",
            "Bot: Beans  Dry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-finetuned\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-finetuned\")\n",
        "\n",
        "# Ensure pad_token is set\n",
        "tokenizer.pad_token = tokenizer.eos_token  # GPT-2 uses eos_token for padding\n",
        "\n",
        "# Generate response with well-structured prompts and advanced generation settings\n",
        "def generate_response(prompt):\n",
        "    # Crafting the prompt for better user interaction\n",
        "    structured_prompt = f\"User: {prompt}\\nBot:\"\n",
        "\n",
        "    # Tokenize and prepare the input\n",
        "    inputs = tokenizer.encode(structured_prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    attention_mask = inputs.ne(tokenizer.pad_token_id).to(inputs.device)  # Create attention mask\n",
        "\n",
        "    # Generate response with temperature, sampling, and pad_token_id adjustments\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=50,  # Adjust the max length of the output response\n",
        "        num_return_sequences=3,  # Number of responses to generate\n",
        "        temperature=0.9,  # Control randomness (higher = more diverse output)\n",
        "        do_sample=True,  # Enable sampling for varied responses\n",
        "        pad_token_id=tokenizer.eos_token_id  # Use eos_token_id as pad_token to prevent issues\n",
        "    )\n",
        "\n",
        "    # Decode and return the response, skipping special tokens\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test the chatbot with different queries\n",
        "print(generate_response(\"What are some high-protein foods?\"))\n",
        "print(generate_response(\"What are low-calorie foods?\"))\n",
        "print(generate_response(\"Can you suggest some balanced foods?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41nX9mIdzvqn",
        "outputId": "478e4c1b-115a-4071-8ddd-3f31a083ae26"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What are some high-protein foods?\n",
            "Bot: Fish  cod.\n",
            "User: What are low-calorie foods?\n",
            "Bot: Almond milk  unsweetened.\n",
            "User: Can you suggest some balanced foods?\n",
            "Bot: Fish  haddock.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6dUlcj7FzvtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FhcN8vgxzvwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSU8pFq1DoaX"
      },
      "source": [
        "## GPT 2 Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKgxhJLIDkeh"
      },
      "outputs": [],
      "source": [
        "# pip install transformers datasets accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEkndck0Dkzt",
        "outputId": "da4c6272-b658-473a-c808-480b87cca426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved as fine_tuning_data.csv!\n"
          ]
        }
      ],
      "source": [
        "# Convert your JSONL file to a dataset with input_text and target_text\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load your JSONL fine-tuning data\n",
        "data = []\n",
        "with open(\"fine_tuning_data.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "# Convert to DataFrame for easier handling\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save in Hugging Face-friendly format\n",
        "df.to_csv(\"fine_tuning_data.csv\", index=False)\n",
        "print(\"Dataset saved as fine_tuning_data.csv!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRksdXohhAbR",
        "outputId": "9b2bd706-c92b-4a16-dc83-2c388f1503a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8907f061e8af419b9f2c7def3241ee95",
            "bc020be3523149fc9b77044dbbdcf3d1",
            "bc448ac7e60c40d6ab4353aff493f643",
            "aa9fb78edc404724affb334d12ae90bd",
            "2aa5f433323a4f1aacf92458de0db4d0",
            "5ac515ee157340b8a860d3439afde4a7",
            "c0ffa4db0d51410da1047f5ea83f75ef",
            "a7b5540599034182bec71dd7144f78a5",
            "e69a4d040abe4a1385ec19cf8e79ce1a",
            "b091223bfd9f4eaeb9cb7ef3ed460b62",
            "bc6476bf1a5e40aeb234ad9fc46b7e0c"
          ]
        },
        "id": "uGWQWITKD9Rt",
        "outputId": "8869008a-668a-41a1-e6be-29be4d4b3532"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8907f061e8af419b9f2c7def3241ee95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': 'I want to lose weight. Is Hummus, commercial good for me?', 'completion': 'Hummus, commercial is not good for weight loss. It has 6.76 kcal per gram.'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"csv\", data_files=\"fine_tuning_data.csv\")\n",
        "train_dataset = dataset[\"train\"]\n",
        "\n",
        "print(train_dataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zBq4mnJECB5",
        "outputId": "e4795ab2-936b-4414-cf58-5175046b1275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to lose weight. Is hummus good for me? No, but I'm going back on that diet because it's a great way to get the most out of my body and not have any issues.\"\n",
            "\"It works,\" said Pauline in response: \"But don't try trying hard at all! You know what you're doing is just getting rid (of) fat cells; they are making up your muscle tissue!\"\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load fine-tuned model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"/content/fine_tuned_distilgpt2\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/fine_tuned_distilgpt2\")\n",
        "\n",
        "# Function to generate responses\n",
        "def generate_response(prompt):\n",
        "    # Tokenize input with padding and truncation\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
        "\n",
        "    # Generate response with improved parameters\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=150,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,  # Enable sampling\n",
        "        top_k=50,  # Limit to top 50 words\n",
        "        top_p=0.9,  # Nucleus sampling\n",
        "        repetition_penalty=2.0,  # Penalize repetition\n",
        "        pad_token_id=tokenizer.pad_token_id  # Proper handling of padding\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test the model\n",
        "prompt = \"I want to lose weight. Is hummus good for me?\"\n",
        "response = generate_response(prompt)\n",
        "print(response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results not so good.\n",
        "\n",
        "### Let's add structure to my prompts for better context."
      ],
      "metadata": {
        "id": "xFRQr2vUwmOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt 2\n",
        "\n",
        "### Added better context + clean response"
      ],
      "metadata": {
        "id": "BkIw87cCzDAm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlMNOazkECEb"
      },
      "outputs": [],
      "source": [
        "def generate_response2(food, goal, question):\n",
        "\n",
        "    # Create structured prompt\n",
        "    prompt = f\"Food: {food}\\nGoal: {goal}\\nQuestion: {question}\"\n",
        "\n",
        "    # Tokenize input with padding and truncation\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
        "\n",
        "    # Generate response with improved parameters\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=150,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=2.0,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    # Decode the output\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ5bdV2OECGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2183543b-3382-49e3-9460-50e534bb4c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Food: Hummus\n",
            "Goal: Weight Loss\n",
            "Question: Is hummus good for me?\n",
            "\n",
            ".I've had it and I'm happy with the results, but still think that if you're not eating a lot of food then your body won't be able to use up all its energy because there's just too much starch in this meal (which is why most people are using beans). If we eat enough grains or pasta every day instead so that our bodies can get used after having eaten whole foods before getting tired from them my weight will go down as well! It'll also help us lose fat faster than any other type diet . Also on top...that being said , don´t expect some kind mass gain during exercise - especially when compared\n"
          ]
        }
      ],
      "source": [
        "# Test the function\n",
        "response = generate_response2(\n",
        "    food=\"Hummus\",\n",
        "    goal=\"Weight Loss\",\n",
        "    question=\"Is hummus good for me?\"\n",
        ")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_response(response):\n",
        "    # Split response into sentences\n",
        "    sentences = response.split(\".\")\n",
        "\n",
        "    # Return the first two sentences for brevity\n",
        "    cleaned_response = \". \".join(sentences[:2]).strip()\n",
        "    return cleaned_response\n",
        "\n",
        "# Test the clean-up\n",
        "response = generate_response2(\n",
        "    food=\"Hummus\",\n",
        "    goal=\"Weight Loss\",\n",
        "    question=\"Is hummus good for me?\"\n",
        ")\n",
        "cleaned_response = clean_response(response)\n",
        "print(cleaned_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9e_AfjpxWcd",
        "outputId": "5f0bc521-3c6d-4dbb-c61b-e248805f88b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Food: Hummus\n",
            "Goal: Weight Loss\n",
            "Question: Is hummus good for me? Answer: Well, I'm a big fan of the stuff it provides.  But when you're not trying to lose weight or make changes in your diet that would be great news! If so then this is an easy recipe with no need on my part (except maybe one) and can help keep people from getting sick over time if they don't want their health restored before long!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Prompt 2"
      ],
      "metadata": {
        "id": "XxC4_izBy_En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1\n",
        "print(generate_response2(\n",
        "    food=\"Bacon\",\n",
        "    goal=\"Weight Loss\",\n",
        "    question=\"Is bacon good for my diet?\"\n",
        "))\n",
        "\n",
        "# Example 2\n",
        "print(generate_response2(\n",
        "    food=\"Eggs\",\n",
        "    goal=\"Muscle Gain\",\n",
        "    question=\"How much protein do eggs have?\"\n",
        "))\n",
        "\n",
        "# Example 3\n",
        "print(generate_response2(\n",
        "    food=\"Chicken\",\n",
        "    goal=\"Weight Loss\",\n",
        "    question=\"Is chicken low in calories?\"\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y6mNozEx4K0",
        "outputId": "c0be69f0-4eac-420c-a477-8e2de3ab2ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Food: Bacon\n",
            "Goal: Weight Loss\n",
            "Question: Is bacon good for my diet? Answer to question 1 of 3. (Click here to download)\n",
            "\n",
            "\n",
            "Food: Eggs\n",
            "Goal: Muscle Gain\n",
            "Question: How much protein do eggs have? Can they help you lose weight and maintain your healthy body mass, or is it something that we should avoid doing at all costs. (Answer) We can't give up on our natural eating habits if there's not enough evidence to support those claims! In fact this has been shown in some studies where women were given a diet consisting of 8% carbohydrate instead thereof which caused them considerable pain for several weeks after the experiment was started due simply because their bodies didn´t metabolize carbs properly by themselves - although I think even more research needs being done regarding how fat intake affects muscle growth... Also please consider what kind \"caffeine\" foods are available from reputable\n",
            "Food: Chicken\n",
            "Goal: Weight Loss\n",
            "Question: Is chicken low in calories? Answer : Yes. However, the high amount of protein and fat found on meat is a major contributing factor to weight loss problems for many people who are considering going vegetarian or vegans over time ( ). The main reasons that vegetarians get lost from their diet include an increased risk factors such as smoking , kidney disease , heart attack/stroke and diabetes . There also seems not enough data available about other potential sources of dietary fiber among those with higher levels than 50% body mass index (<25 kg) but this issue has been debated by researchers before because it may be associated either directly related intake habits which have changed along some evolutionary history toward greater food-dieting behaviors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of Issues\n",
        "\n",
        "Verbose and Unstructured Output: the model generates overly long and irrelevant sentences because it lacks focus. The prompt structure is not effectively guiding the model's behavior.\n",
        "\n",
        "Lack of Domain-Specific Knowledge:the model relies too heavily on pre-trained general knowledge rather than fine-tuned task-specific examples.\n",
        "\n",
        "Unclear Training Signal: the fine-tuning data may not have enough diversity or explicit examples to enforce concise, factual, and relevant outputs."
      ],
      "metadata": {
        "id": "Tz49FcMRznFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt 3\n",
        "\n",
        "### Added explicit instructions"
      ],
      "metadata": {
        "id": "Vn57BlKGzHyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response3(food, goal, question):\n",
        "    # Create structured and constrained prompt\n",
        "    prompt = (\n",
        "        \"Here is an example:\\n\"\n",
        "        \"Food: Bacon\\n\"\n",
        "        \"Goal: Weight Loss\\n\"\n",
        "        \"Question: Is bacon good for weight loss?\\n\"\n",
        "        \"Answer: No, bacon is high in calories and fat, making it a poor choice for weight loss.\\n\\n\"\n",
        "        \"Now, answer the following:\\n\"\n",
        "        f\"Food: {food}\\n\"\n",
        "        f\"Goal: {goal}\\n\"\n",
        "        f\"Question: Is {food} good for {goal}?\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
        "\n",
        "    # Generate response with constraints\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=150,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=2.5,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "JOollRB4x7S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_response2(response):\n",
        "    # Extract sentences and look for a clear answer\n",
        "    sentences = response.split(\". \")\n",
        "\n",
        "    # Return only the first sentence containing the key context\n",
        "    for sentence in sentences:\n",
        "        if \"calorie\" in sentence.lower() or \"protein\" in sentence.lower() or \"fat\" in sentence.lower():\n",
        "            return sentence.strip()\n",
        "\n",
        "    # Fallback: Return the first sentence if no key context is found\n",
        "    return sentences[0].strip()\n"
      ],
      "metadata": {
        "id": "HcFHKKuIzgWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function with the new structure\n",
        "response = generate_response3(\n",
        "    food=\"Hummus\",\n",
        "    goal=\"Weight Loss\",\n",
        "    question=\"Is hummus good for me?\"\n",
        ")\n",
        "cleaned_response = clean_response2(response)\n",
        "print(\"Cleaned Response:\", cleaned_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGFsRgosz3g2",
        "outputId": "45ef4d52-4708-4445-d0a9-6baf171eb3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Response: Here is an example:\n",
            "Food: Bacon\n",
            "Goal: Weight Loss\n",
            "Question: Is bacon good for weight loss?\n",
            "Answer: No, bacon is high in calories and fat, making it a poor choice for weight loss.\n",
            "\n",
            "Now, answer the following:\n",
            "Food: Hummus\n",
            "Goal: Weight Loss\n",
            "Question: Is Hummus good for Weight Loss?\n",
            "Answer: Yes – I don't think so! It's not even close to that level of calorie restriction you're talking about here…it really isn`t like eating too much food at once or anything!! All we have left are two options (no more than 2 meals per day) with one being very low-carb while another could be either lean meatless veggies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt 4\n",
        "\n",
        "### Added facts"
      ],
      "metadata": {
        "id": "yWnUPb9N1pv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_with_facts(food, facts, goal):\n",
        "    # Add structured prompt with facts\n",
        "    prompt = (\n",
        "        f\"Food: {food}\\n\"\n",
        "        f\"Facts: {facts}\\n\"\n",
        "        f\"Goal: {goal}\\n\"\n",
        "        f\"Question: Is {food} good for {goal}?\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
        "\n",
        "    # Generate response\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=100,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=2.5,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test with factual data\n",
        "facts = \"Hummus contains 166 calories and 7.9g of protein per serving.\"\n",
        "response = generate_response_with_facts(food=\"Hummus\", facts=facts, goal=\"Weight Loss\")\n",
        "print(\"Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzhyv5B4z-rM",
        "outputId": "27de23b7-4f63-469a-aacc-bd7cc923c68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Food: Hummus\n",
            "Facts: Hummus contains 166 calories and 7.9g of protein per serving.\n",
            "Goal: Weight Loss\n",
            "Question: Is Hummus good for Weight Loss?\n",
            "Answer: It does not cause any weight loss, but it may lead to a temporary decrease in your body's ability \"to digest fats\" or produce energy that is lost when you lose fat (in other words gain muscle mass). In addition there are various types available which will help reduce the amount spent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_response_contextual(response):\n",
        "    # Split response into sentences\n",
        "    sentences = response.split(\". \")\n",
        "\n",
        "    # Look for key context in sentences\n",
        "    for sentence in sentences:\n",
        "        if any(keyword in sentence.lower() for keyword in [\"yes\", \"no\", \"calorie\", \"protein\", \"fat\"]):\n",
        "            return sentence.strip()\n",
        "\n",
        "    # Default: Return the first sentence\n",
        "    return sentences[0].strip()\n"
      ],
      "metadata": {
        "id": "FgMSobPJ1yLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facts = \"Hummus contains 166 calories and 7.9g of protein per serving.\"\n",
        "response = generate_response_with_facts(food=\"Hummus\", facts=facts, goal=\"Weight Loss\")\n",
        "cleaned_response = clean_response_contextual(response)\n",
        "print(\"Cleaned Response:\", cleaned_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2R3arrs2VYl",
        "outputId": "d74cf430-ac34-45c8-831f-c1aa83ad5f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Response: Food: Hummus\n",
            "Facts: Hummus contains 166 calories and 7.9g of protein per serving.\n",
            "Goal: Weight Loss\n",
            "Question: Is Hummus good for Weight Loss?\n",
            "Answer: It is an excellent source, particularly if you're looking to lose weight in a healthy way or when working out hard (no one knows how it works)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Facts really helped the answers."
      ],
      "metadata": {
        "id": "rK_K1qRm2iUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load dataset\n",
        "with open(\"foundationDownload.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract the list of foods\n",
        "foods = data[\"FoundationFoods\"]\n",
        "\n",
        "# Function to extract key nutrients\n",
        "def process_food_data(foods):\n",
        "    processed_data = []\n",
        "    for food in foods:\n",
        "        description = food.get(\"description\", \"Unknown\")\n",
        "        nutrients = food.get(\"foodNutrients\", [])\n",
        "\n",
        "        # Extract nutrient amounts\n",
        "        nutrient_dict = {n[\"nutrient\"][\"name\"]: n[\"amount\"] for n in nutrients if \"amount\" in n}\n",
        "\n",
        "        # Extract relevant nutrients\n",
        "        important_nutrients = {\n",
        "            \"Description\": description,\n",
        "            \"Calories\": nutrient_dict.get(\"Energy\", 0),\n",
        "            \"Protein\": nutrient_dict.get(\"Protein\", 0),\n",
        "            \"Fat\": nutrient_dict.get(\"Total lipid (fat)\", 0),\n",
        "        }\n",
        "        processed_data.append(important_nutrients)\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "# Process food data\n",
        "processed_foods = process_food_data(foods)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZhMgKq934Yxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_foods[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0q_nylP4bPg",
        "outputId": "ab92d465-2a8f-47d6-e01d-5525326a8df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Description': 'Hummus, commercial',\n",
              " 'Calories': 229,\n",
              " 'Protein': 7.35,\n",
              " 'Fat': 17.1}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompts(processed_foods):\n",
        "    prompts = []\n",
        "    for food in processed_foods:\n",
        "        description = food[\"Description\"]\n",
        "        calories = food[\"Calories\"]\n",
        "        protein = food[\"Protein\"]\n",
        "        fat = food[\"Fat\"]\n",
        "\n",
        "        # Generate prompt for weight loss\n",
        "        weight_loss_prompt = {\n",
        "            \"prompt\": f\"Food: {description}\\nFacts: {calories} calories, {protein}g protein, {fat}g fat per serving.\\nGoal: Weight Loss\\nQuestion: Is {description} good for weight loss?\\nAnswer:\",\n",
        "            \"completion\": f\" Yes, {description} is low in calories and high in protein, making it a good choice for weight loss when eaten in moderation.\"\n",
        "        }\n",
        "\n",
        "        # Generate prompt for muscle gain\n",
        "        muscle_gain_prompt = {\n",
        "            \"prompt\": f\"Food: {description}\\nFacts: {calories} calories, {protein}g protein, {fat}g fat per serving.\\nGoal: Muscle Gain\\nQuestion: Is {description} good for muscle gain?\\nAnswer:\",\n",
        "            \"completion\": f\" Yes, {description} is high in protein, making it an excellent choice for muscle gain.\"\n",
        "        }\n",
        "\n",
        "        prompts.extend([weight_loss_prompt, muscle_gain_prompt])\n",
        "\n",
        "    return prompts\n",
        "\n",
        "# Generate prompts\n",
        "prompts = generate_prompts(processed_foods)\n",
        "\n",
        "# Save to JSONL file\n",
        "with open(\"fine_tuning_prompts.jsonl\", \"w\") as f:\n",
        "    for item in prompts:\n",
        "        json.dump(item, f)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(\"Prompts saved to fine_tuning_prompts.jsonl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T0EPv8g4eIN",
        "outputId": "f2fd9076-00c9-416d-cb38-10ebd2bb8cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompts saved to fine_tuning_prompts.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the JSONL dataset\n",
        "dataset = load_dataset(\"json\", data_files={\"train\": \"fine_tuning_prompts.jsonl\"})\n",
        "\n",
        "# Split into train and validation sets (90% train, 10% validation)\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"test\"]\n",
        "\n",
        "print(train_dataset[0])  # Check the structure\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "0vbrZlnn5M2w",
        "outputId": "3ee4e4dc-805b-44c2-8ee2-3eb7a7255cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Unable to find '/content/fine_tuning_prompts.jsonl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-255c53b7fcb0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the JSONL dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"fine_tuning_prompts.jsonl\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Split into train and validation sets (90% train, 10% validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2132\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   2133\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m         ).get_module()\n\u001b[0m\u001b[1;32m   1563\u001b[0m     \u001b[0;31m# Try locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mget_data_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         )\n\u001b[0;32m--> 942\u001b[0;31m         data_files = DataFilesDict.from_patterns(\n\u001b[0m\u001b[1;32m    943\u001b[0m             \u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mfrom_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFilesList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 else DataFilesList.from_patterns(\n\u001b[0m\u001b[1;32m    722\u001b[0m                     \u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mfrom_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 data_files.extend(\n\u001b[0;32m--> 624\u001b[0;31m                     resolve_pattern(\n\u001b[0m\u001b[1;32m    625\u001b[0m                         \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                         \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mallowed_extensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\" with any supported extension {list(allowed_extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find '/content/fine_tuning_prompts.jsonl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = \"distilgpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Add padding token if not present\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4bahhs55kLE",
        "outputId": "5e614b10-313c-46dc-d2d1-538057f446a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50258, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    # Combine prompt and completion with a separator\n",
        "    full_text = [f\"{prompt} [SEP] {completion}\" for prompt, completion in zip(examples[\"prompt\"], examples[\"completion\"])]\n",
        "    return tokenizer(\n",
        "        full_text,\n",
        "        truncation=True,  # Truncate sequences longer than max_length\n",
        "        max_length=512,  # Ensure consistent token lengths\n",
        "        padding=\"max_length\"  # Add padding for consistent lengths\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "t2lWXG2Y5pKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Remove unnecessary columns\n",
        "train_dataset = train_dataset.remove_columns([\"prompt\", \"completion\"])\n",
        "eval_dataset = eval_dataset.remove_columns([\"prompt\", \"completion\"])\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format(\"torch\")\n",
        "eval_dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "magXpnDy52VP",
        "outputId": "dde01ce0-88b5-44d7-ccb5-6c68c232e44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c1051545f7a0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tokenize datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0meval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Remove unnecessary columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8907f061e8af419b9f2c7def3241ee95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc020be3523149fc9b77044dbbdcf3d1",
              "IPY_MODEL_bc448ac7e60c40d6ab4353aff493f643",
              "IPY_MODEL_aa9fb78edc404724affb334d12ae90bd"
            ],
            "layout": "IPY_MODEL_2aa5f433323a4f1aacf92458de0db4d0"
          }
        },
        "bc020be3523149fc9b77044dbbdcf3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ac515ee157340b8a860d3439afde4a7",
            "placeholder": "​",
            "style": "IPY_MODEL_c0ffa4db0d51410da1047f5ea83f75ef",
            "value": "Generating train split: "
          }
        },
        "bc448ac7e60c40d6ab4353aff493f643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7b5540599034182bec71dd7144f78a5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e69a4d040abe4a1385ec19cf8e79ce1a",
            "value": 1
          }
        },
        "aa9fb78edc404724affb334d12ae90bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b091223bfd9f4eaeb9cb7ef3ed460b62",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6476bf1a5e40aeb234ad9fc46b7e0c",
            "value": " 632/0 [00:00&lt;00:00, 3441.61 examples/s]"
          }
        },
        "2aa5f433323a4f1aacf92458de0db4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac515ee157340b8a860d3439afde4a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ffa4db0d51410da1047f5ea83f75ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7b5540599034182bec71dd7144f78a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e69a4d040abe4a1385ec19cf8e79ce1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b091223bfd9f4eaeb9cb7ef3ed460b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6476bf1a5e40aeb234ad9fc46b7e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aba2cc363dde45c38f3d8cfba3d3c744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2102069b54041df905f738869c0fe2d",
              "IPY_MODEL_933831a6bae1459095ffc1f02faa57ec",
              "IPY_MODEL_287aabe26eac49c0a0966f4e680cba28"
            ],
            "layout": "IPY_MODEL_bc033873f40a4f0c86bda589455695c3"
          }
        },
        "d2102069b54041df905f738869c0fe2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e8cc5f3d1594cc38ca4855a02c04071",
            "placeholder": "​",
            "style": "IPY_MODEL_f14e056c3b744c86bc33d4c68e9f7c93",
            "value": "Generating train split: "
          }
        },
        "933831a6bae1459095ffc1f02faa57ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0d8b937e6c343bda7935cc205b6659f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6395cb7d3d84e91acaf9f3a2e5fcdde",
            "value": 1
          }
        },
        "287aabe26eac49c0a0966f4e680cba28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa905bbb1304472b91641932d6c5412",
            "placeholder": "​",
            "style": "IPY_MODEL_686632dbf84b4f7fb1a9443d67b4c88f",
            "value": " 1240/0 [00:00&lt;00:00, 5981.42 examples/s]"
          }
        },
        "bc033873f40a4f0c86bda589455695c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8cc5f3d1594cc38ca4855a02c04071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f14e056c3b744c86bc33d4c68e9f7c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0d8b937e6c343bda7935cc205b6659f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d6395cb7d3d84e91acaf9f3a2e5fcdde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7aa905bbb1304472b91641932d6c5412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "686632dbf84b4f7fb1a9443d67b4c88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1fdc9e5836b405d98b09381ef88af2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3f659f5eea546349634a0897b6c5340",
              "IPY_MODEL_3b1feec7784d45108e4be8bde771b16c",
              "IPY_MODEL_613c3a386f1843c8b5f21d3b458e48dc"
            ],
            "layout": "IPY_MODEL_2b3bf080fbcb427da4c34b5944a78d5c"
          }
        },
        "c3f659f5eea546349634a0897b6c5340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef6cf1a86c464aa499a693a986f5f231",
            "placeholder": "​",
            "style": "IPY_MODEL_9d31d49b4bcc40719281448b75756de2",
            "value": "Map: 100%"
          }
        },
        "3b1feec7784d45108e4be8bde771b16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd89a616e61c47438b922657e0c7b981",
            "max": 1240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af56b87b82d54c9f8adb0dd99058b914",
            "value": 1240
          }
        },
        "613c3a386f1843c8b5f21d3b458e48dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fac20148555449f84ad4d0401c48848",
            "placeholder": "​",
            "style": "IPY_MODEL_f85b164afc4c4bc3937e4c708c7a0a28",
            "value": " 1240/1240 [00:00&lt;00:00, 2638.10 examples/s]"
          }
        },
        "2b3bf080fbcb427da4c34b5944a78d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef6cf1a86c464aa499a693a986f5f231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d31d49b4bcc40719281448b75756de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd89a616e61c47438b922657e0c7b981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af56b87b82d54c9f8adb0dd99058b914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fac20148555449f84ad4d0401c48848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f85b164afc4c4bc3937e4c708c7a0a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}