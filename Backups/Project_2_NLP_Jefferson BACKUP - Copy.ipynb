{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMsU9t-s8Scp"
      },
      "source": [
        "## NLP PROJECT #2\n",
        "\n",
        "### Student: Jefferson Roesler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaJQs_3S8bcK"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNN_kJjY8bj-"
      },
      "source": [
        "### Function to Calculate Calories and Protein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ut5Myot8Rpf",
        "outputId": "966716be-0f69-48fd-c9f5-fbc1aa3d1ec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'calories_per_day': 3094.31, 'protein_per_day': 140}\n"
          ]
        }
      ],
      "source": [
        "def calculate_calories_and_protein(weight, height, age, gender, activity_level, goal):\n",
        "\n",
        "    # Mifflin-St Jeor BMR calculation\n",
        "    if gender.lower() == \"male\":\n",
        "        bmr = 10 * weight + 6.25 * height - 5 * age + 5\n",
        "    elif gender.lower() == \"female\":\n",
        "        bmr = 10 * weight + 6.25 * height - 5 * age - 161\n",
        "    else:\n",
        "        raise ValueError(\"Gender must be 'male' or 'female'\")\n",
        "\n",
        "    # Activity factor based on steps and workouts\n",
        "    activity_factors = {\n",
        "        \"sedentary\": 1.2,  # Less than 5,000 steps a day, no workouts\n",
        "        \"lightly active\": 1.375,  # ~5,000 steps/day, 1-3 workouts/week\n",
        "        \"moderately active\": 1.55,  # ~7,000-10,000 steps/day, 2-5 workouts/week\n",
        "        \"very active\": 1.725  # More than 10,000 steps/day, 3-6 workouts/week\n",
        "    }\n",
        "    if activity_level not in activity_factors:\n",
        "        raise ValueError(f\"Invalid activity level. Choose from: {list(activity_factors.keys())}\")\n",
        "\n",
        "    # Adjust BMR by activity level\n",
        "    calories = bmr * activity_factors[activity_level]\n",
        "\n",
        "    # Adjust for goal\n",
        "    if goal == \"weight loss\":\n",
        "        calories -= 500  # Subtract 500 calories for a deficit\n",
        "    elif goal == \"muscle gain\":\n",
        "        calories += 500  # Add 500 calories for a surplus\n",
        "\n",
        "    # Protein intake: 2 grams per kilogram of body weight\n",
        "    protein = weight * 2  # Protein in grams\n",
        "\n",
        "    return {\n",
        "        \"calories_per_day\": round(calories, 2),\n",
        "        \"protein_per_day\": round(protein, 2)\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "result = calculate_calories_and_protein(\n",
        "    weight=70,\n",
        "    height=175,\n",
        "    age=25,\n",
        "    gender=\"male\",\n",
        "    activity_level=\"moderately active\",\n",
        "    goal=\"muscle gain\"\n",
        ")\n",
        "\n",
        "print(result)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grr3ZB_U8m-X",
        "outputId": "db63b429-9535-46f7-9a6e-37e93192bab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daily recommended calories and proteins: {'calories_per_day': 3243.5, 'protein_per_day': 168}\n"
          ]
        }
      ],
      "source": [
        "# Test inputs\n",
        "test_input = {\n",
        "    \"weight\": 84,              # kg\n",
        "    \"height\": 180,             # cm\n",
        "    \"age\": 40,                 # years\n",
        "    \"gender\": \"male\",          # \"male\" or \"female\"\n",
        "    \"activity_level\": \"moderately active\",  # Activity level\n",
        "    \"goal\": \"muscle gain\"      # Goal: \"weight loss\", \"maintenance\", or \"weight gain\"\n",
        "}\n",
        "\n",
        "# Calculate calories\n",
        "results = calculate_calories_and_protein(\n",
        "    weight=test_input[\"weight\"],\n",
        "    height=test_input[\"height\"],\n",
        "    age=test_input[\"age\"],\n",
        "    gender=test_input[\"gender\"],\n",
        "    activity_level=test_input[\"activity_level\"],\n",
        "    goal=test_input[\"goal\"]\n",
        ")\n",
        "\n",
        "print(f\"Daily recommended calories and proteins: {results}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMIVphsx8voU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwaG1nTZ_8Mu"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hHgVzUu82fo"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the JSON file\n",
        "with open('foundationDownload.json', 'r') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3s3LefYQxbz",
        "outputId": "5cbfc60b-979e-46d8-af14-07b74d262043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Description  Serving Size (g)  \\\n",
            "0                                 Hummus, commercial              33.9   \n",
            "1                               Tomatoes, grape, raw              49.7   \n",
            "2  Beans, snap, green, canned, regular pack, drai...             129.0   \n",
            "3                        Frankfurter, beef, unheated              48.6   \n",
            "4        Nuts, almonds, dry roasted, with salt added             135.0   \n",
            "\n",
            "   Calories  Protein  Carbohydrates    Fat  \n",
            "0     229.0     7.35          14.90  17.10  \n",
            "1     113.0     0.83           5.51   0.63  \n",
            "2      86.0     1.04           4.11   0.39  \n",
            "3    1310.0    11.70           2.89  28.00  \n",
            "4    2590.0    20.40          16.20  57.80  \n"
          ]
        }
      ],
      "source": [
        "# Extract the list of foods\n",
        "foods = data[\"FoundationFoods\"]\n",
        "\n",
        "# Flatten the data and include serving size\n",
        "def process_food_data_with_serving_size(foods):\n",
        "    processed_data = []\n",
        "    for food in foods:\n",
        "        # Extract food description\n",
        "        description = food.get(\"description\", \"Unknown\")\n",
        "\n",
        "        # Extract serving size (from 'foodPortions')\n",
        "        food_portions = food.get(\"foodPortions\", [])\n",
        "        if food_portions:\n",
        "            # Assume the first portion is the standard serving size\n",
        "            serving_size = food_portions[0].get(\"gramWeight\", 0)  # Weight in grams\n",
        "        else:\n",
        "            serving_size = 0  # Default if no portion info available\n",
        "\n",
        "        # Extract nutrients\n",
        "        nutrients = food.get(\"foodNutrients\", [])\n",
        "        nutrient_dict = {n[\"nutrient\"][\"name\"]: n[\"amount\"] for n in nutrients if \"amount\" in n}\n",
        "\n",
        "        # Keep only key nutrients and serving size\n",
        "        important_nutrients = {\n",
        "            \"Description\": description,\n",
        "            \"Serving Size (g)\": serving_size,\n",
        "            \"Calories\": nutrient_dict.get(\"Energy\", 0),\n",
        "            \"Protein\": nutrient_dict.get(\"Protein\", 0),\n",
        "            \"Carbohydrates\": nutrient_dict.get(\"Carbohydrate, by difference\", 0),\n",
        "            \"Fat\": nutrient_dict.get(\"Total lipid (fat)\", 0)\n",
        "        }\n",
        "        processed_data.append(important_nutrients)\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "# Process the food data with serving size\n",
        "processed_foods_with_serving_size = process_food_data_with_serving_size(foods)\n",
        "\n",
        "# Convert to a Pandas DataFrame for easier handling\n",
        "food_df_with_serving_size = pd.DataFrame(processed_foods_with_serving_size)\n",
        "\n",
        "# Display the first few rows\n",
        "print(food_df_with_serving_size.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GOmLv8v_5o8"
      },
      "source": [
        "## Add columns for calories/protein per gram.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBVYerHO8s0w",
        "outputId": "86518148-53d3-455a-961f-f91771cf1e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                         Description  Serving Size (g)  \\\n",
            "0                                 Hummus, commercial              33.9   \n",
            "1                               Tomatoes, grape, raw              49.7   \n",
            "2  Beans, snap, green, canned, regular pack, drai...             129.0   \n",
            "3                        Frankfurter, beef, unheated              48.6   \n",
            "4        Nuts, almonds, dry roasted, with salt added             135.0   \n",
            "\n",
            "   Calories  Protein  Carbohydrates    Fat  Calories per Gram  \\\n",
            "0     229.0     7.35          14.90  17.10           6.755162   \n",
            "1     113.0     0.83           5.51   0.63           2.273642   \n",
            "2      86.0     1.04           4.11   0.39           0.666667   \n",
            "3    1310.0    11.70           2.89  28.00          26.954733   \n",
            "4    2590.0    20.40          16.20  57.80          19.185185   \n",
            "\n",
            "   Protein per Gram  \n",
            "0          0.216814  \n",
            "1          0.016700  \n",
            "2          0.008062  \n",
            "3          0.240741  \n",
            "4          0.151111  \n"
          ]
        }
      ],
      "source": [
        "# Add new columns for calories and protein per gram\n",
        "food_df_with_serving_size[\"Calories per Gram\"] = food_df_with_serving_size[\"Calories\"] / food_df_with_serving_size[\"Serving Size (g)\"]\n",
        "food_df_with_serving_size[\"Protein per Gram\"] = food_df_with_serving_size[\"Protein\"] / food_df_with_serving_size[\"Serving Size (g)\"]\n",
        "\n",
        "# Replace infinite or NaN values (e.g., where serving size is 0)\n",
        "food_df_with_serving_size.replace([float('inf'), float('-inf')], 0, inplace=True)\n",
        "food_df_with_serving_size.fillna(0, inplace=True)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(food_df_with_serving_size.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDSfL1S0_4VQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMDuBS6dAyYI"
      },
      "source": [
        "## User Profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCtu0A4m_4Xk",
        "outputId": "259c8ee1-772c-4102-8154-c2928ac7250a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User profile created!\n",
            "{'weight': 70, 'height': 175, 'age': 25, 'gender': 'male', 'activity_level': 'moderately active', 'goal': 'muscle gain', 'calories_per_day': 3094.31, 'protein_per_day': 140}\n"
          ]
        }
      ],
      "source": [
        "# Define a global variable for the user profile\n",
        "user_profile = {}\n",
        "\n",
        "# Function to set up the user profile\n",
        "def set_user_profile(weight, height, age, gender, activity_level, goal):\n",
        "    global user_profile\n",
        "    # Use the existing calculator to determine calories and protein\n",
        "    user_data = calculate_calories_and_protein(\n",
        "        weight=weight,\n",
        "        height=height,\n",
        "        age=age,\n",
        "        gender=gender,\n",
        "        activity_level=activity_level,\n",
        "        goal=goal\n",
        "    )\n",
        "    # Store the data in the user profile\n",
        "    user_profile = {\n",
        "        \"weight\": weight,\n",
        "        \"height\": height,\n",
        "        \"age\": age,\n",
        "        \"gender\": gender,\n",
        "        \"activity_level\": activity_level,\n",
        "        \"goal\": goal,\n",
        "        \"calories_per_day\": user_data[\"calories_per_day\"],\n",
        "        \"protein_per_day\": user_data[\"protein_per_day\"]\n",
        "    }\n",
        "    print(\"User profile created!\")\n",
        "    return user_profile\n",
        "\n",
        "# Example usage\n",
        "user_profile = set_user_profile(\n",
        "    weight=70, height=175, age=25, gender=\"male\",\n",
        "    activity_level=\"moderately active\", goal=\"muscle gain\"\n",
        ")\n",
        "\n",
        "print(user_profile)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT-1NVcEA3qh",
        "outputId": "8fc56fbf-abcc-4272-9089-1138156ac5b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your daily calorie goal is 3094.31 kcal, and your protein goal is 140 g.\n"
          ]
        }
      ],
      "source": [
        "# Function to get user-specific needs\n",
        "def get_user_needs():\n",
        "    if not user_profile:\n",
        "        return \"No user profile found. Please set up your profile first.\"\n",
        "    return f\"Your daily calorie goal is {user_profile['calories_per_day']} kcal, and your protein goal is {user_profile['protein_per_day']} g.\"\n",
        "\n",
        "# Example usage\n",
        "print(get_user_needs())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwuQoYoTA_ho"
      },
      "source": [
        "## Food Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZczE_RqwA8Nl"
      },
      "outputs": [],
      "source": [
        "# Evaluate food based on user profile\n",
        "def evaluate_food_personalized(food_name, df):\n",
        "    if not user_profile:\n",
        "        return \"Please set up your user profile first.\"\n",
        "\n",
        "    # Fetch food details\n",
        "    food_details = get_food_details(food_name, df)\n",
        "    if isinstance(food_details, str):  # If food not found\n",
        "        return food_details\n",
        "\n",
        "    # Extract user-specific goals\n",
        "    goal = user_profile[\"goal\"]\n",
        "    daily_calories = user_profile[\"calories_per_day\"]\n",
        "    daily_protein = user_profile[\"protein_per_day\"]\n",
        "\n",
        "    # Extract food details\n",
        "    calories_per_gram = food_details[\"Calories per Gram\"]\n",
        "    protein_per_gram = food_details[\"Protein per Gram\"]\n",
        "\n",
        "    # Evaluate based on goal\n",
        "    if goal == \"weight loss\":\n",
        "        if calories_per_gram > 2:\n",
        "            return f\"{food_name} is calorie-dense ({calories_per_gram:.2f} kcal/g), so it may not align with your weight loss goal.\"\n",
        "        else:\n",
        "            return f\"{food_name} is low in calories ({calories_per_gram:.2f} kcal/g) and fits your weight loss goal!\"\n",
        "    elif goal == \"muscle gain\":\n",
        "        if protein_per_gram > 0.2:\n",
        "            return f\"{food_name} is rich in protein ({protein_per_gram:.2f} g/g), making it great for muscle gain.\"\n",
        "        else:\n",
        "            return f\"{food_name} has low protein content ({protein_per_gram:.2f} g/g), so it might not be ideal for muscle gain.\"\n",
        "    else:\n",
        "        return \"Invalid goal in profile. Please set a valid goal.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m--o23QCCMv6"
      },
      "outputs": [],
      "source": [
        "# Search for food details by name\n",
        "def get_food_details(food_name, df):\n",
        "    # Find the food item in the dataset\n",
        "    match = df[df[\"Description\"].str.contains(food_name, case=False, na=False)]\n",
        "    if match.empty:\n",
        "        return f\"Sorry, I couldn't find any information on '{food_name}'.\"\n",
        "    else:\n",
        "        return match.iloc[0].to_dict()  # Return the first match as a dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JST9SDePB0v1"
      },
      "outputs": [],
      "source": [
        "# Evaluate food based on user profile\n",
        "def evaluate_food_personalized(food_name, df):\n",
        "    if not user_profile:\n",
        "        return \"Please set up your user profile first.\"\n",
        "\n",
        "    # Fetch food details\n",
        "    food_details = get_food_details(food_name, df)\n",
        "    if isinstance(food_details, str):  # If food not found\n",
        "        return food_details\n",
        "\n",
        "    # Extract user-specific goals\n",
        "    goal = user_profile[\"goal\"]\n",
        "    daily_calories = user_profile[\"calories_per_day\"]\n",
        "    daily_protein = user_profile[\"protein_per_day\"]\n",
        "\n",
        "    # Extract food details\n",
        "    calories_per_gram = food_details[\"Calories per Gram\"]\n",
        "    protein_per_gram = food_details[\"Protein per Gram\"]\n",
        "\n",
        "    # Evaluate based on goal\n",
        "    if goal == \"weight loss\":\n",
        "        if calories_per_gram > 2:\n",
        "            return f\"{food_name} is calorie-dense ({calories_per_gram:.2f} kcal/g), so it may not align with your weight loss goal.\"\n",
        "        else:\n",
        "            return f\"{food_name} is low in calories ({calories_per_gram:.2f} kcal/g) and fits your weight loss goal!\"\n",
        "    elif goal == \"muscle gain\":\n",
        "        if protein_per_gram > 0.2:\n",
        "            return f\"{food_name} is rich in protein ({protein_per_gram:.2f} g/g), making it great for muscle gain.\"\n",
        "        else:\n",
        "            return f\"{food_name} has low protein content ({protein_per_gram:.2f} g/g), so it might not be ideal for muscle gain.\"\n",
        "    else:\n",
        "        return \"Invalid goal in profile. Please set a valid goal.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ9oU6qFBHDh"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJDnx8faBIAH",
        "outputId": "6f5e3ac3-1ab6-45da-fb5f-86e12334fee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! Let's set up your profile.\n",
            "Enter your weight (kg): 84\n",
            "Enter your height (cm): 180\n",
            "Enter your age: 39\n",
            "Enter your gender (male/female): male\n",
            "Enter your activity level (sedentary/lightly active/moderately active/very active): moderately active\n",
            "What is your goal? (weight loss/muscle gain): muscle gain\n",
            "User profile created!\n",
            "\n",
            "Your profile has been created.\n",
            "Your daily calorie goal is 3251.25 kcal, and your protein goal is 168.0 g.\n",
            "\n",
            "Enter the name of a food to evaluate (or type 'exit' to quit): garlic\n",
            "garlic has low protein content (0.00 g/g), so it might not be ideal for muscle gain.\n",
            "\n",
            "Enter the name of a food to evaluate (or type 'exit' to quit): exit\n",
            "Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# Interactive script\n",
        "def interactive_test(df):\n",
        "    print(\"Welcome! Let's set up your profile.\")\n",
        "    weight = float(input(\"Enter your weight (kg): \"))\n",
        "    height = float(input(\"Enter your height (cm): \"))\n",
        "    age = int(input(\"Enter your age: \"))\n",
        "    gender = input(\"Enter your gender (male/female): \")\n",
        "    activity_level = input(\"Enter your activity level (sedentary/lightly active/moderately active/very active): \")\n",
        "    goal = input(\"What is your goal? (weight loss/muscle gain): \").lower()\n",
        "\n",
        "    # Set up the profile\n",
        "    set_user_profile(weight, height, age, gender, activity_level, goal)\n",
        "\n",
        "    print(\"\\nYour profile has been created.\")\n",
        "    print(get_user_needs())\n",
        "\n",
        "    while True:\n",
        "        # Ask about food\n",
        "        food_name = input(\"\\nEnter the name of a food to evaluate (or type 'exit' to quit): \")\n",
        "        if food_name.lower() == \"exit\":\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "        evaluation = evaluate_food_personalized(food_name, df)\n",
        "        print(evaluation)\n",
        "\n",
        "# Run the interactive test\n",
        "interactive_test(food_df_with_serving_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iodTTkMEDHox"
      },
      "source": [
        "## Enhance Chatbot Responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDNHpvwPDIGV"
      },
      "outputs": [],
      "source": [
        "# Enhanced conversational responses\n",
        "def evaluate_food_personalized(food_name, df):\n",
        "    if not user_profile:\n",
        "        return \"Please set up your user profile first.\"\n",
        "\n",
        "    # Fetch food details\n",
        "    food_details = get_food_details(food_name, df)\n",
        "    if isinstance(food_details, str):  # If food not found\n",
        "        return food_details\n",
        "\n",
        "    # Extract user-specific goals\n",
        "    goal = user_profile[\"goal\"]\n",
        "    calories_per_gram = food_details[\"Calories per Gram\"]\n",
        "    protein_per_gram = food_details[\"Protein per Gram\"]\n",
        "\n",
        "    # Friendly responses\n",
        "    if goal == \"weight loss\":\n",
        "        if calories_per_gram > 2:\n",
        "            return (\n",
        "                f\"{food_name.capitalize()} has {calories_per_gram:.2f} kcal per gram, \"\n",
        "                \"which is a bit calorie-dense. It might not be the best option if you're trying to lose weight, \"\n",
        "                \"but you can still enjoy it in moderation!\"\n",
        "            )\n",
        "        else:\n",
        "            return (\n",
        "                f\"{food_name.capitalize()} is a great choice for weight loss! \"\n",
        "                f\"It has just {calories_per_gram:.2f} kcal per gram, making it a low-calorie option.\"\n",
        "            )\n",
        "    elif goal == \"muscle gain\":\n",
        "        if protein_per_gram > 0.2:\n",
        "            return (\n",
        "                f\"{food_name.capitalize()} is rich in protein with {protein_per_gram:.2f} g per gram. \"\n",
        "                \"It's a fantastic option to support your muscle gain goals!\"\n",
        "            )\n",
        "        else:\n",
        "            return (\n",
        "                f\"{food_name.capitalize()} has {protein_per_gram:.2f} g of protein per gram, \"\n",
        "                \"which is relatively low. You might want to choose higher-protein foods.\"\n",
        "            )\n",
        "    else:\n",
        "        return \"Invalid goal in profile. Please set a valid goal (weight loss or muscle gain).\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26KWcU_YDPDo"
      },
      "source": [
        "## Generate Fine-Tuning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGoq1CXuDLNv",
        "outputId": "403e2f0d-ea94-4ae3-a760-d72594adc86e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning data saved as fine_tuning_data.jsonl!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Generate fine-tuning data\n",
        "def generate_fine_tuning_data(df):\n",
        "    fine_tuning_data = []\n",
        "    for _, row in df.iterrows():\n",
        "        food_name = row[\"Description\"]\n",
        "        calories_per_gram = row[\"Calories per Gram\"]\n",
        "        protein_per_gram = row[\"Protein per Gram\"]\n",
        "\n",
        "        # Add Q&A examples\n",
        "        fine_tuning_data.append({\n",
        "            \"prompt\": f\"I want to lose weight. Is {food_name} good for me?\",\n",
        "            \"completion\": (\n",
        "                f\"{food_name} {'is' if calories_per_gram <= 2 else 'is not'} good for weight loss. \"\n",
        "                f\"It has {calories_per_gram:.2f} kcal per gram.\"\n",
        "            )\n",
        "        })\n",
        "        fine_tuning_data.append({\n",
        "            \"prompt\": f\"I want to gain muscle. Is {food_name} a good choice?\",\n",
        "            \"completion\": (\n",
        "                f\"{food_name} {'is' if protein_per_gram > 0.2 else 'is not'} a good choice for muscle gain. \"\n",
        "                f\"It contains {protein_per_gram:.2f} g of protein per gram.\"\n",
        "            )\n",
        "        })\n",
        "\n",
        "    return fine_tuning_data\n",
        "\n",
        "# Generate data\n",
        "fine_tuning_data = generate_fine_tuning_data(food_df_with_serving_size)\n",
        "\n",
        "# Save to JSONL file\n",
        "with open(\"fine_tuning_data.jsonl\", \"w\") as f:\n",
        "    for item in fine_tuning_data:\n",
        "        json.dump(item, f)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(\"Fine-tuning data saved as fine_tuning_data.jsonl!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSU8pFq1DoaX"
      },
      "source": [
        "## GPT 2 Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKgxhJLIDkeh"
      },
      "outputs": [],
      "source": [
        "# pip install transformers datasets accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEkndck0Dkzt",
        "outputId": "da4c6272-b658-473a-c808-480b87cca426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved as fine_tuning_data.csv!\n"
          ]
        }
      ],
      "source": [
        "# Convert your JSONL file to a dataset with input_text and target_text\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load your JSONL fine-tuning data\n",
        "data = []\n",
        "with open(\"fine_tuning_data.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "# Convert to DataFrame for easier handling\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save in Hugging Face-friendly format\n",
        "df.to_csv(\"fine_tuning_data.csv\", index=False)\n",
        "print(\"Dataset saved as fine_tuning_data.csv!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRksdXohhAbR",
        "outputId": "9b2bd706-c92b-4a16-dc83-2c388f1503a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "8907f061e8af419b9f2c7def3241ee95",
            "bc020be3523149fc9b77044dbbdcf3d1",
            "bc448ac7e60c40d6ab4353aff493f643",
            "aa9fb78edc404724affb334d12ae90bd",
            "2aa5f433323a4f1aacf92458de0db4d0",
            "5ac515ee157340b8a860d3439afde4a7",
            "c0ffa4db0d51410da1047f5ea83f75ef",
            "a7b5540599034182bec71dd7144f78a5",
            "e69a4d040abe4a1385ec19cf8e79ce1a",
            "b091223bfd9f4eaeb9cb7ef3ed460b62",
            "bc6476bf1a5e40aeb234ad9fc46b7e0c"
          ]
        },
        "id": "uGWQWITKD9Rt",
        "outputId": "8869008a-668a-41a1-e6be-29be4d4b3532"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8907f061e8af419b9f2c7def3241ee95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': 'I want to lose weight. Is Hummus, commercial good for me?', 'completion': 'Hummus, commercial is not good for weight loss. It has 6.76 kcal per gram.'}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"csv\", data_files=\"fine_tuning_data.csv\")\n",
        "train_dataset = dataset[\"train\"]\n",
        "\n",
        "print(train_dataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zBq4mnJECB5",
        "outputId": "e4795ab2-936b-4414-cf58-5175046b1275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to lose weight. Is hummus good for me? No, but I'm going back on that diet because it's a great way to get the most out of my body and not have any issues.\"\n",
            "\"It works,\" said Pauline in response: \"But don't try trying hard at all! You know what you're doing is just getting rid (of) fat cells; they are making up your muscle tissue!\"\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load fine-tuned model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\"/content/fine_tuned_distilgpt2\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/fine_tuned_distilgpt2\")\n",
        "\n",
        "# Function to generate responses\n",
        "def generate_response(prompt):\n",
        "    # Tokenize input with padding and truncation\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
        "\n",
        "    # Generate response with improved parameters\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=150,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,  # Enable sampling\n",
        "        top_k=50,  # Limit to top 50 words\n",
        "        top_p=0.9,  # Nucleus sampling\n",
        "        repetition_penalty=2.0,  # Penalize repetition\n",
        "        pad_token_id=tokenizer.pad_token_id  # Proper handling of padding\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test the model\n",
        "prompt = \"I want to lose weight. Is hummus good for me?\"\n",
        "response = generate_response(prompt)\n",
        "print(response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results not so good.\n",
        "\n",
        "### Let's add structure to my prompts for better context."
      ],
      "metadata": {
        "id": "xFRQr2vUwmOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt 2\n",
        "\n",
        "### Added better context + clean response"
      ],
      "metadata": {
        "id": "BkIw87cCzDAm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlMNOazkECEb"
      },
      "outputs": [],
      "source": [
        "def generate_response2(food, goal, question):\n",
        "\n",
        "    # Create structured prompt\n",
        "    prompt = f\"Food: {food}\\nGoal: {goal}\\nQuestion: {question}\"\n",
        "\n",
        "    # Tokenize input with padding and truncation\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
        "\n",
        "    # Generate response with improved parameters\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=150,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=2.0,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    # Decode the output\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ5bdV2OECGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2183543b-3382-49e3-9460-50e534bb4c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Food: Hummus\n",
            "Goal: Weight Loss\n",
            "Question: Is hummus good for me?\n",
            "\n",
            ".I've had it and I'm happy with the results, but still think that if you're not eating a lot of food then your body won't be able to use up all its energy because there's just too much starch in this meal (which is why most people are using beans). If we eat enough grains or pasta every day instead so that our bodies can get used after having eaten whole foods before getting tired from them my weight will go down as well! It'll also help us lose fat faster than any other type diet . Also on top...that being said , don´t expect some kind mass gain during exercise - especially when compared\n"
          ]
        }
      ],
      "source": [
        "# Test the function\n",
        "response = generate_response2(\n",
        "    food=\"Hummus\",\n",
        "    goal=\"Weight Loss\",\n",
        "    question=\"Is hummus good for me?\"\n",
        ")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_response(response):\n",
        "    # Split response into sentences\n",
        "    sentences = response.split(\".\")\n",
        "\n",
        "    # Return the first two sentences for brevity\n",
        "    cleaned_response = \". \".join(sentences[:2]).strip()\n",
        "    return cleaned_response\n",
        "\n",
        "# Test the clean-up\n",
        "response = generate_response2(\n",
        "    food=\"Hummus\",\n",
        "    goal=\"Weight Loss\",\n",
        "    question=\"Is hummus good for me?\"\n",
        ")\n",
        "cleaned_response = clean_response(response)\n",
        "print(cleaned_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9e_AfjpxWcd",
        "outputId": "5f0bc521-3c6d-4dbb-c61b-e248805f88b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Food: Hummus\n",
            "Goal: Weight Loss\n",
            "Question: Is hummus good for me? Answer: Well, I'm a big fan of the stuff it provides.  But when you're not trying to lose weight or make changes in your diet that would be great news! If so then this is an easy recipe with no need on my part (except maybe one) and can help keep people from getting sick over time if they don't want their health restored before long!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Prompt 2"
      ],
      "metadata": {
        "id": "XxC4_izBy_En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1\n",
        "print(generate_response2(\n",
        "    food=\"Bacon\",\n",
        "    goal=\"Weight Loss\",\n",
        "    question=\"Is bacon good for my diet?\"\n",
        "))\n",
        "\n",
        "# Example 2\n",
        "print(generate_response2(\n",
        "    food=\"Eggs\",\n",
        "    goal=\"Muscle Gain\",\n",
        "    question=\"How much protein do eggs have?\"\n",
        "))\n",
        "\n",
        "# Example 3\n",
        "print(generate_response2(\n",
        "    food=\"Chicken\",\n",
        "    goal=\"Weight Loss\",\n",
        "    question=\"Is chicken low in calories?\"\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y6mNozEx4K0",
        "outputId": "c0be69f0-4eac-420c-a477-8e2de3ab2ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Food: Bacon\n",
            "Goal: Weight Loss\n",
            "Question: Is bacon good for my diet? Answer to question 1 of 3. (Click here to download)\n",
            "\n",
            "\n",
            "Food: Eggs\n",
            "Goal: Muscle Gain\n",
            "Question: How much protein do eggs have? Can they help you lose weight and maintain your healthy body mass, or is it something that we should avoid doing at all costs. (Answer) We can't give up on our natural eating habits if there's not enough evidence to support those claims! In fact this has been shown in some studies where women were given a diet consisting of 8% carbohydrate instead thereof which caused them considerable pain for several weeks after the experiment was started due simply because their bodies didn´t metabolize carbs properly by themselves - although I think even more research needs being done regarding how fat intake affects muscle growth... Also please consider what kind \"caffeine\" foods are available from reputable\n",
            "Food: Chicken\n",
            "Goal: Weight Loss\n",
            "Question: Is chicken low in calories? Answer : Yes. However, the high amount of protein and fat found on meat is a major contributing factor to weight loss problems for many people who are considering going vegetarian or vegans over time ( ). The main reasons that vegetarians get lost from their diet include an increased risk factors such as smoking , kidney disease , heart attack/stroke and diabetes . There also seems not enough data available about other potential sources of dietary fiber among those with higher levels than 50% body mass index (<25 kg) but this issue has been debated by researchers before because it may be associated either directly related intake habits which have changed along some evolutionary history toward greater food-dieting behaviors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of Issues\n",
        "\n",
        "Verbose and Unstructured Output: the model generates overly long and irrelevant sentences because it lacks focus. The prompt structure is not effectively guiding the model's behavior.\n",
        "\n",
        "Lack of Domain-Specific Knowledge:the model relies too heavily on pre-trained general knowledge rather than fine-tuned task-specific examples.\n",
        "\n",
        "Unclear Training Signal: the fine-tuning data may not have enough diversity or explicit examples to enforce concise, factual, and relevant outputs."
      ],
      "metadata": {
        "id": "Tz49FcMRznFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt 3\n",
        "\n",
        "### Added explicit instructions"
      ],
      "metadata": {
        "id": "Vn57BlKGzHyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response3(food, goal, question):\n",
        "    # Create structured and constrained prompt\n",
        "    prompt = (\n",
        "        \"Here is an example:\\n\"\n",
        "        \"Food: Bacon\\n\"\n",
        "        \"Goal: Weight Loss\\n\"\n",
        "        \"Question: Is bacon good for weight loss?\\n\"\n",
        "        \"Answer: No, bacon is high in calories and fat, making it a poor choice for weight loss.\\n\\n\"\n",
        "        \"Now, answer the following:\\n\"\n",
        "        f\"Food: {food}\\n\"\n",
        "        f\"Goal: {goal}\\n\"\n",
        "        f\"Question: Is {food} good for {goal}?\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
        "\n",
        "    # Generate response with constraints\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=150,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=2.5,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "JOollRB4x7S8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_response2(response):\n",
        "    # Extract sentences and look for a clear answer\n",
        "    sentences = response.split(\". \")\n",
        "\n",
        "    # Return only the first sentence containing the key context\n",
        "    for sentence in sentences:\n",
        "        if \"calorie\" in sentence.lower() or \"protein\" in sentence.lower() or \"fat\" in sentence.lower():\n",
        "            return sentence.strip()\n",
        "\n",
        "    # Fallback: Return the first sentence if no key context is found\n",
        "    return sentences[0].strip()\n"
      ],
      "metadata": {
        "id": "HcFHKKuIzgWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function with the new structure\n",
        "response = generate_response3(\n",
        "    food=\"Hummus\",\n",
        "    goal=\"Weight Loss\",\n",
        "    question=\"Is hummus good for me?\"\n",
        ")\n",
        "cleaned_response = clean_response2(response)\n",
        "print(\"Cleaned Response:\", cleaned_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGFsRgosz3g2",
        "outputId": "45ef4d52-4708-4445-d0a9-6baf171eb3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Response: Here is an example:\n",
            "Food: Bacon\n",
            "Goal: Weight Loss\n",
            "Question: Is bacon good for weight loss?\n",
            "Answer: No, bacon is high in calories and fat, making it a poor choice for weight loss.\n",
            "\n",
            "Now, answer the following:\n",
            "Food: Hummus\n",
            "Goal: Weight Loss\n",
            "Question: Is Hummus good for Weight Loss?\n",
            "Answer: Yes – I don't think so! It's not even close to that level of calorie restriction you're talking about here…it really isn`t like eating too much food at once or anything!! All we have left are two options (no more than 2 meals per day) with one being very low-carb while another could be either lean meatless veggies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt 4\n",
        "\n",
        "### Added facts"
      ],
      "metadata": {
        "id": "yWnUPb9N1pv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response_with_facts(food, facts, goal):\n",
        "    # Add structured prompt with facts\n",
        "    prompt = (\n",
        "        f\"Food: {food}\\n\"\n",
        "        f\"Facts: {facts}\\n\"\n",
        "        f\"Goal: {goal}\\n\"\n",
        "        f\"Question: Is {food} good for {goal}?\\n\"\n",
        "        \"Answer:\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
        "\n",
        "    # Generate response\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=100,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=2.5,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test with factual data\n",
        "facts = \"Hummus contains 166 calories and 7.9g of protein per serving.\"\n",
        "response = generate_response_with_facts(food=\"Hummus\", facts=facts, goal=\"Weight Loss\")\n",
        "print(\"Response:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzhyv5B4z-rM",
        "outputId": "27de23b7-4f63-469a-aacc-bd7cc923c68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Food: Hummus\n",
            "Facts: Hummus contains 166 calories and 7.9g of protein per serving.\n",
            "Goal: Weight Loss\n",
            "Question: Is Hummus good for Weight Loss?\n",
            "Answer: It does not cause any weight loss, but it may lead to a temporary decrease in your body's ability \"to digest fats\" or produce energy that is lost when you lose fat (in other words gain muscle mass). In addition there are various types available which will help reduce the amount spent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_response_contextual(response):\n",
        "    # Split response into sentences\n",
        "    sentences = response.split(\". \")\n",
        "\n",
        "    # Look for key context in sentences\n",
        "    for sentence in sentences:\n",
        "        if any(keyword in sentence.lower() for keyword in [\"yes\", \"no\", \"calorie\", \"protein\", \"fat\"]):\n",
        "            return sentence.strip()\n",
        "\n",
        "    # Default: Return the first sentence\n",
        "    return sentences[0].strip()\n"
      ],
      "metadata": {
        "id": "FgMSobPJ1yLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facts = \"Hummus contains 166 calories and 7.9g of protein per serving.\"\n",
        "response = generate_response_with_facts(food=\"Hummus\", facts=facts, goal=\"Weight Loss\")\n",
        "cleaned_response = clean_response_contextual(response)\n",
        "print(\"Cleaned Response:\", cleaned_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2R3arrs2VYl",
        "outputId": "d74cf430-ac34-45c8-831f-c1aa83ad5f89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Response: Food: Hummus\n",
            "Facts: Hummus contains 166 calories and 7.9g of protein per serving.\n",
            "Goal: Weight Loss\n",
            "Question: Is Hummus good for Weight Loss?\n",
            "Answer: It is an excellent source, particularly if you're looking to lose weight in a healthy way or when working out hard (no one knows how it works)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Facts really helped the answers."
      ],
      "metadata": {
        "id": "rK_K1qRm2iUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load dataset\n",
        "with open(\"foundationDownload.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract the list of foods\n",
        "foods = data[\"FoundationFoods\"]\n",
        "\n",
        "# Function to extract key nutrients\n",
        "def process_food_data(foods):\n",
        "    processed_data = []\n",
        "    for food in foods:\n",
        "        description = food.get(\"description\", \"Unknown\")\n",
        "        nutrients = food.get(\"foodNutrients\", [])\n",
        "\n",
        "        # Extract nutrient amounts\n",
        "        nutrient_dict = {n[\"nutrient\"][\"name\"]: n[\"amount\"] for n in nutrients if \"amount\" in n}\n",
        "\n",
        "        # Extract relevant nutrients\n",
        "        important_nutrients = {\n",
        "            \"Description\": description,\n",
        "            \"Calories\": nutrient_dict.get(\"Energy\", 0),\n",
        "            \"Protein\": nutrient_dict.get(\"Protein\", 0),\n",
        "            \"Fat\": nutrient_dict.get(\"Total lipid (fat)\", 0),\n",
        "        }\n",
        "        processed_data.append(important_nutrients)\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "# Process food data\n",
        "processed_foods = process_food_data(foods)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZhMgKq934Yxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_foods[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0q_nylP4bPg",
        "outputId": "ab92d465-2a8f-47d6-e01d-5525326a8df7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Description': 'Hummus, commercial',\n",
              " 'Calories': 229,\n",
              " 'Protein': 7.35,\n",
              " 'Fat': 17.1}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompts(processed_foods):\n",
        "    prompts = []\n",
        "    for food in processed_foods:\n",
        "        description = food[\"Description\"]\n",
        "        calories = food[\"Calories\"]\n",
        "        protein = food[\"Protein\"]\n",
        "        fat = food[\"Fat\"]\n",
        "\n",
        "        # Generate prompt for weight loss\n",
        "        weight_loss_prompt = {\n",
        "            \"prompt\": f\"Food: {description}\\nFacts: {calories} calories, {protein}g protein, {fat}g fat per serving.\\nGoal: Weight Loss\\nQuestion: Is {description} good for weight loss?\\nAnswer:\",\n",
        "            \"completion\": f\" Yes, {description} is low in calories and high in protein, making it a good choice for weight loss when eaten in moderation.\"\n",
        "        }\n",
        "\n",
        "        # Generate prompt for muscle gain\n",
        "        muscle_gain_prompt = {\n",
        "            \"prompt\": f\"Food: {description}\\nFacts: {calories} calories, {protein}g protein, {fat}g fat per serving.\\nGoal: Muscle Gain\\nQuestion: Is {description} good for muscle gain?\\nAnswer:\",\n",
        "            \"completion\": f\" Yes, {description} is high in protein, making it an excellent choice for muscle gain.\"\n",
        "        }\n",
        "\n",
        "        prompts.extend([weight_loss_prompt, muscle_gain_prompt])\n",
        "\n",
        "    return prompts\n",
        "\n",
        "# Generate prompts\n",
        "prompts = generate_prompts(processed_foods)\n",
        "\n",
        "# Save to JSONL file\n",
        "with open(\"fine_tuning_prompts.jsonl\", \"w\") as f:\n",
        "    for item in prompts:\n",
        "        json.dump(item, f)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(\"Prompts saved to fine_tuning_prompts.jsonl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T0EPv8g4eIN",
        "outputId": "f2fd9076-00c9-416d-cb38-10ebd2bb8cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompts saved to fine_tuning_prompts.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the JSONL dataset\n",
        "dataset = load_dataset(\"json\", data_files={\"train\": \"fine_tuning_prompts.jsonl\"})\n",
        "\n",
        "# Split into train and validation sets (90% train, 10% validation)\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"test\"]\n",
        "\n",
        "print(train_dataset[0])  # Check the structure\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "0vbrZlnn5M2w",
        "outputId": "3ee4e4dc-805b-44c2-8ee2-3eb7a7255cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Unable to find '/content/fine_tuning_prompts.jsonl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-255c53b7fcb0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the JSONL dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"fine_tuning_prompts.jsonl\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Split into train and validation sets (90% train, 10% validation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2132\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   2133\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m         ).get_module()\n\u001b[0m\u001b[1;32m   1563\u001b[0m     \u001b[0;31m# Try locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mget_data_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         )\n\u001b[0;32m--> 942\u001b[0;31m         data_files = DataFilesDict.from_patterns(\n\u001b[0m\u001b[1;32m    943\u001b[0m             \u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mfrom_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFilesList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m                 else DataFilesList.from_patterns(\n\u001b[0m\u001b[1;32m    722\u001b[0m                     \u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mfrom_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 data_files.extend(\n\u001b[0;32m--> 624\u001b[0;31m                     resolve_pattern(\n\u001b[0m\u001b[1;32m    625\u001b[0m                         \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                         \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mallowed_extensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\" with any supported extension {list(allowed_extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find '/content/fine_tuning_prompts.jsonl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model_name = \"distilgpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Add padding token if not present\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4bahhs55kLE",
        "outputId": "5e614b10-313c-46dc-d2d1-538057f446a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50258, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    # Combine prompt and completion with a separator\n",
        "    full_text = [f\"{prompt} [SEP] {completion}\" for prompt, completion in zip(examples[\"prompt\"], examples[\"completion\"])]\n",
        "    return tokenizer(\n",
        "        full_text,\n",
        "        truncation=True,  # Truncate sequences longer than max_length\n",
        "        max_length=512,  # Ensure consistent token lengths\n",
        "        padding=\"max_length\"  # Add padding for consistent lengths\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "t2lWXG2Y5pKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Remove unnecessary columns\n",
        "train_dataset = train_dataset.remove_columns([\"prompt\", \"completion\"])\n",
        "eval_dataset = eval_dataset.remove_columns([\"prompt\", \"completion\"])\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format(\"torch\")\n",
        "eval_dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "magXpnDy52VP",
        "outputId": "dde01ce0-88b5-44d7-ccb5-6c68c232e44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c1051545f7a0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tokenize datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0meval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Remove unnecessary columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8907f061e8af419b9f2c7def3241ee95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc020be3523149fc9b77044dbbdcf3d1",
              "IPY_MODEL_bc448ac7e60c40d6ab4353aff493f643",
              "IPY_MODEL_aa9fb78edc404724affb334d12ae90bd"
            ],
            "layout": "IPY_MODEL_2aa5f433323a4f1aacf92458de0db4d0"
          }
        },
        "bc020be3523149fc9b77044dbbdcf3d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ac515ee157340b8a860d3439afde4a7",
            "placeholder": "​",
            "style": "IPY_MODEL_c0ffa4db0d51410da1047f5ea83f75ef",
            "value": "Generating train split: "
          }
        },
        "bc448ac7e60c40d6ab4353aff493f643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7b5540599034182bec71dd7144f78a5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e69a4d040abe4a1385ec19cf8e79ce1a",
            "value": 1
          }
        },
        "aa9fb78edc404724affb334d12ae90bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b091223bfd9f4eaeb9cb7ef3ed460b62",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6476bf1a5e40aeb234ad9fc46b7e0c",
            "value": " 632/0 [00:00&lt;00:00, 3441.61 examples/s]"
          }
        },
        "2aa5f433323a4f1aacf92458de0db4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac515ee157340b8a860d3439afde4a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0ffa4db0d51410da1047f5ea83f75ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7b5540599034182bec71dd7144f78a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e69a4d040abe4a1385ec19cf8e79ce1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b091223bfd9f4eaeb9cb7ef3ed460b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6476bf1a5e40aeb234ad9fc46b7e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}